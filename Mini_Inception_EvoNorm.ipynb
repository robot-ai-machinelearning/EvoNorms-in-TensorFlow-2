{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini_Inception_EvoNorm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM26e3nPFZWbF//xZs4mED7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/EvoNorms-in-TensorFlow-2/blob/master/Mini_Inception_EvoNorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vov59PhnHH5J",
        "colab_type": "code",
        "outputId": "af84e7af-322d-49c5-f770-8543c5459e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Which GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 19 03:18:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chf8mjl60M-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c5360b4-1a46-4f22-83c7-e885d1dee42f"
      },
      "source": [
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MszMKRN0nti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other imports\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DyzD6hk0rjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the random seeds\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wOz0xzLF8zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up wandb for easy experiment tracking\n",
        "!pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssVHc5nh0w0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load and preprocess CIFAR10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255.\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udzb5ADxHYcM",
        "colab_type": "text"
      },
      "source": [
        "## `EvoNorm2dB0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PMnIekD0yTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference\n",
        "# https://github.com/lonePatient/EvoNorms_PyTorch/blob/master/models/normalization.py\n",
        "\n",
        "def instance_std(x, eps=1e-5):\n",
        "\t# https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
        "\t_, var = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
        "\treturn tf.sqrt(var + eps)\n",
        "\n",
        "class EvoNorm2dB0(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, in_channels, nonlinear=True, momentum=0.9,\n",
        "\t\teps=1e-5):\n",
        "\t\tsuper(EvoNorm2dB0, self).__init__()\n",
        "\t\tself.nonlinear = nonlinear\n",
        "\t\tself.momentum = momentum\n",
        "\t\tself.eps = eps\n",
        "\t\tself.running_var = tf.ones((1, in_channels, 1, 1))\n",
        "\n",
        "\t\tdef build(self):\n",
        "\t\t\tself.gamma = self.add_variable(\"gamma\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, 1, 1, self.in_channels),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Ones())\n",
        "\t\t\tself.beta = self.add_variable(\"beta\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, 1, 1, self.in_channels),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Zeros())\n",
        "\t\t\tif self.nonlinear:\n",
        "\t\t\t\tself.v = self.add_variable(\"v\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, 1, 1, self.in_channels),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Ones())\n",
        "\n",
        "\t\tdef call(self, x):\n",
        "\t\t\tN, H, W, C = tf.shape(x)\n",
        "\n",
        "\t\t\tif self.training:\n",
        "\t\t\t\tx1 = tf.transpose(x, [3, 0, 1, 2])\n",
        "\t\t\t\tx1 = tf.reshape(x1, (C, -1))\n",
        "\t\t\t\tvar = tf.math.reduce_std(x1, axis=1)\n",
        "\t\t\t\tvar = tf.reshape(var, (1, C, 1, 1))\n",
        "\t\t\t\tself.running_var = self.momentum * self.running_var + (1 - self.momentum) * var\n",
        "\t\t\telse:\n",
        "\t\t\t\tvar = self.running_var\n",
        "\n",
        "\t\t\tif self.nonlinear:\n",
        "\t\t\t\tden = tf.math.maximum(tf.sqrt(var+self.eps), self.v * x + instance_std(x))\n",
        "\t\t\t\treturn x / den * self.gamma + self.beta\n",
        "\t\t\telse:\n",
        "\t\t\t\treturn x * self.gamma + self.beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "katzf-j4Hb3-",
        "colab_type": "text"
      },
      "source": [
        "## `EvoNorm2dS0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPpctYba05Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference\n",
        "# https://github.com/lonePatient/EvoNorms_PyTorch/blob/master/models/normalization.py\n",
        "\n",
        "def group_std(x, groups=32, eps=1e-5):\n",
        "\tN, H, W, C = tf.shape(x)\n",
        "\tx = tf.reshape(x, [N, H, W, groups, C // groups])\n",
        "\t_, var = tf.nn.moments(x, [1, 2, 4], keepdims=True)\n",
        "\tstd = tf.sqrt(var + eps)\n",
        "\tstd = tf.broadcast_to(std, x.shape)\n",
        "\treturn tf.reshape(std, (N, H, W, C))\n",
        "\n",
        "class EvoNorm2dS0(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, in_channels, groups=32, nonlinear=True):\n",
        "\t\tsuper(EvoNorm2dS0, self).__init__()\n",
        "\t\tself.nonlinear = nonlinear\n",
        "\t\tself.groups = groups\n",
        "\n",
        "\t\tdef build(self):\n",
        "\t\t\tself.gamma = self.add_variable(\"gamma\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, 1, 1, self.in_channels),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Ones())\n",
        "\t\t\tself.beta = self.add_variable(\"beta\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, 1, 1, self.in_channels),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Zeros())\n",
        "\t\t\tif self.nonlinear:\n",
        "\t\t\t\tself.v = self.add_variable(\"v\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, 1, 1, self.in_channels),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Ones())\n",
        "\n",
        "\t\tdef call(self, x):\n",
        "\t\t\tif self.nonlinear:\n",
        "\t\t\t\tnum = x * tf.nn.sigmoid(self.v * x)\n",
        "\t\t\t\treturn num / group_std(x) * self.gamma + self.beta\n",
        "\t\t\telse:\n",
        "\t\t\t\treturn x * self.gamma + self.beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngt39WlcSBH0",
        "colab_type": "text"
      },
      "source": [
        "## Mini Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgeN8DMD1Cze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementation comes from http://pyimg.co/mac01\n",
        "def minigooglenet_functional(width, height, depth, classes, norm=EvoNorm2dB0, groups=32):\n",
        "\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\n",
        "\t\t# define a CONV => EvoNorm pattern\n",
        "\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n",
        "\t\t\n",
        "\t\tif isinstance(norm, EvoNorm2dS0):\n",
        "\t\t\tlayer = norm(in_channels=K, groups=groups)\n",
        "\t\telse:\n",
        "\t\t\tlayer = norm(in_channels=K)\n",
        "\t\t\n",
        "\t\tx = layer(x)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef inception_module(x, numK1x1, numK3x3, chanDim):\n",
        "\t\t# define two CONV modules, then concatenate across the\n",
        "\t\t# channel dimension\n",
        "\t\tconv_1x1 = conv_module(x, numK1x1, 1, 1, (1, 1), chanDim)\n",
        "\t\tconv_3x3 = conv_module(x, numK3x3, 3, 3, (1, 1), chanDim)\n",
        "\t\tx = concatenate([conv_1x1, conv_3x3], axis=chanDim)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef downsample_module(x, K, chanDim):\n",
        "\t\t# define the CONV module and POOL, then concatenate\n",
        "\t\t# across the channel dimensions\n",
        "\t\tconv_3x3 = conv_module(x, K, 3, 3, (2, 2), chanDim,\n",
        "\t\t\tpadding=\"valid\")\n",
        "\t\tpool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\t\tx = concatenate([conv_3x3, pool], axis=chanDim)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\t# initialize the input shape to be \"channels last\" and the\n",
        "\t# channels dimension itself\n",
        "\tinputShape = (height, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\t# define the model input and first CONV module\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = conv_module(inputs, 96, 3, 3, (1, 1), chanDim)\n",
        "\n",
        "\t# two Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 32, 32, chanDim)\n",
        "\tx = inception_module(x, 32, 48, chanDim)\n",
        "\tx = downsample_module(x, 80, chanDim)\n",
        "\n",
        "\t# four Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 112, 48, chanDim)\n",
        "\tx = inception_module(x, 96, 64, chanDim)\n",
        "\tx = inception_module(x, 80, 80, chanDim)\n",
        "\tx = inception_module(x, 48, 96, chanDim)\n",
        "\tx = downsample_module(x, 96, chanDim)\n",
        "\n",
        "\t# two Inception modules followed by global POOL and dropout\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = AveragePooling2D((7, 7))(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\n",
        "\t# softmax classifier\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(classes)(x)\n",
        "\tx = Activation(\"softmax\")(x)\n",
        "\n",
        "\t# create the model\n",
        "\tmodel = Model(inputs, x, name=\"minigooglenet\")\n",
        "\n",
        "\t# return the constructed network architecture\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V99JZ-ip1n9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding of the labels\n",
        "y_train_ohe = tf.keras.utils.to_categorical(y_train)\n",
        "y_test_ohe = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDc4snWZ1yVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE=128\n",
        "EPOCHS=60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f4aTbCFGUn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import wandb's Keras callback\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qihy4IiF3DrS",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dB0` and no data agumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AiXZhQ5189_",
        "colab_type": "code",
        "outputId": "3f2c9694-20cf-427c-ae6a-d2353ba6a0c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"EvoNorm2dB0-no-data-aug\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dB0-no-data-aug\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dB0-no-data-aug</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8571 - accuracy: 0.3165"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Layer EvoNorm2dB0 has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 16s 40ms/step - loss: 1.8571 - accuracy: 0.3165 - val_loss: 1.4914 - val_accuracy: 0.4620\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.3633 - accuracy: 0.5123 - val_loss: 1.2440 - val_accuracy: 0.5731\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.1808 - accuracy: 0.5867 - val_loss: 1.1303 - val_accuracy: 0.6196\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 1.0726 - accuracy: 0.6252 - val_loss: 1.0465 - val_accuracy: 0.6301\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.9877 - accuracy: 0.6604 - val_loss: 0.9531 - val_accuracy: 0.6687\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.9143 - accuracy: 0.6875 - val_loss: 0.8937 - val_accuracy: 0.6884\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.8561 - accuracy: 0.7047 - val_loss: 0.8441 - val_accuracy: 0.7105\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.8061 - accuracy: 0.7252 - val_loss: 0.8901 - val_accuracy: 0.6948\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.7622 - accuracy: 0.7408 - val_loss: 0.7921 - val_accuracy: 0.7334\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.7289 - accuracy: 0.7481 - val_loss: 0.8101 - val_accuracy: 0.7206\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.6934 - accuracy: 0.7629 - val_loss: 0.7334 - val_accuracy: 0.7488\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.6590 - accuracy: 0.7753 - val_loss: 0.7706 - val_accuracy: 0.7370\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.6255 - accuracy: 0.7853 - val_loss: 0.7773 - val_accuracy: 0.7419\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.5980 - accuracy: 0.7948 - val_loss: 0.7553 - val_accuracy: 0.7447\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.5677 - accuracy: 0.8050 - val_loss: 0.8386 - val_accuracy: 0.7262\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.5398 - accuracy: 0.8135 - val_loss: 0.7904 - val_accuracy: 0.7474\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.5140 - accuracy: 0.8231 - val_loss: 0.7644 - val_accuracy: 0.7550\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4917 - accuracy: 0.8300 - val_loss: 0.7880 - val_accuracy: 0.7425\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4504 - accuracy: 0.8438 - val_loss: 0.7595 - val_accuracy: 0.7677\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4347 - accuracy: 0.8479 - val_loss: 0.8086 - val_accuracy: 0.7450\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4127 - accuracy: 0.8551 - val_loss: 0.7942 - val_accuracy: 0.7593\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3908 - accuracy: 0.8637 - val_loss: 0.8229 - val_accuracy: 0.7515\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3718 - accuracy: 0.8694 - val_loss: 0.8331 - val_accuracy: 0.7509\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.3497 - accuracy: 0.8788 - val_loss: 0.9344 - val_accuracy: 0.7324\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3275 - accuracy: 0.8852 - val_loss: 0.8543 - val_accuracy: 0.7571\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3061 - accuracy: 0.8911 - val_loss: 0.9141 - val_accuracy: 0.7516\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2973 - accuracy: 0.8946 - val_loss: 0.8897 - val_accuracy: 0.7537\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2742 - accuracy: 0.9032 - val_loss: 0.9028 - val_accuracy: 0.7566\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2600 - accuracy: 0.9077 - val_loss: 0.8955 - val_accuracy: 0.7630\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2435 - accuracy: 0.9129 - val_loss: 0.9550 - val_accuracy: 0.7546\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2117 - accuracy: 0.9237 - val_loss: 1.1205 - val_accuracy: 0.7387\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.2115 - accuracy: 0.9247 - val_loss: 1.0641 - val_accuracy: 0.7490\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2063 - accuracy: 0.9248 - val_loss: 1.0993 - val_accuracy: 0.7431\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1773 - accuracy: 0.9373 - val_loss: 1.1415 - val_accuracy: 0.7412\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1898 - accuracy: 0.9325 - val_loss: 1.0990 - val_accuracy: 0.7485\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1678 - accuracy: 0.9405 - val_loss: 1.1924 - val_accuracy: 0.7421\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1556 - accuracy: 0.9452 - val_loss: 1.2313 - val_accuracy: 0.7370\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1625 - accuracy: 0.9426 - val_loss: 1.2492 - val_accuracy: 0.7483\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1292 - accuracy: 0.9544 - val_loss: 1.2762 - val_accuracy: 0.7440\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1208 - accuracy: 0.9576 - val_loss: 1.2141 - val_accuracy: 0.7566\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1191 - accuracy: 0.9586 - val_loss: 1.3175 - val_accuracy: 0.7507\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1204 - accuracy: 0.9578 - val_loss: 1.3059 - val_accuracy: 0.7538\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1068 - accuracy: 0.9626 - val_loss: 1.3403 - val_accuracy: 0.7493\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.0940 - accuracy: 0.9672 - val_loss: 1.3512 - val_accuracy: 0.7525\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1090 - accuracy: 0.9617 - val_loss: 1.4125 - val_accuracy: 0.7523\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0839 - accuracy: 0.9713 - val_loss: 1.5469 - val_accuracy: 0.7370\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0834 - accuracy: 0.9711 - val_loss: 1.3577 - val_accuracy: 0.7602\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 1.4711 - val_accuracy: 0.7511\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0602 - accuracy: 0.9797 - val_loss: 1.5902 - val_accuracy: 0.7518\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0750 - accuracy: 0.9741 - val_loss: 1.5572 - val_accuracy: 0.7526\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0624 - accuracy: 0.9785 - val_loss: 1.5390 - val_accuracy: 0.7498\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0626 - accuracy: 0.9785 - val_loss: 1.6788 - val_accuracy: 0.7483\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0846 - accuracy: 0.9714 - val_loss: 1.4792 - val_accuracy: 0.7652\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0449 - accuracy: 0.9849 - val_loss: 1.6814 - val_accuracy: 0.7455\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 1.5640 - val_accuracy: 0.7620\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 1.6593 - val_accuracy: 0.7642\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 1.7681 - val_accuracy: 0.7586\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 1.7806 - val_accuracy: 0.7592\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0331 - accuracy: 0.9885 - val_loss: 1.8629 - val_accuracy: 0.7493\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 1.8099 - val_accuracy: 0.7512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85mX7gnbPn5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try with data augmentation\n",
        "aug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=18, \n",
        "    zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, \n",
        "    shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWIx1ixlMIw-",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dB0` and data agumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6jZNL60MLun",
        "colab_type": "code",
        "outputId": "96fe1aa0-1f4b-484b-fc9a-4d0e8c54f7bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"EvoNorm2dB0-data-aug\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dB0-data-aug\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dB0-data-aug</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 13s 33ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1023 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0968 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0967 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1027 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1018 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0948 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1015 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1031 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0971 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1065 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0969 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyOaJyNMAkAe",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` and no data augmentation (groups of 8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db6InWQdAg1l",
        "colab_type": "code",
        "outputId": "f0ce39be-72a6-4c93-a24a-a3631838de05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"EvoNorm2dS0-no-aug-group8\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=8)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-no-aug-group8\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-no-aug-group8</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7933 - accuracy: 0.3336"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Layer EvoNorm2dS0 has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 16s 40ms/step - loss: 1.7933 - accuracy: 0.3336 - val_loss: 1.5026 - val_accuracy: 0.4582\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.3575 - accuracy: 0.5188 - val_loss: 1.1937 - val_accuracy: 0.5863\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.1718 - accuracy: 0.5894 - val_loss: 1.1102 - val_accuracy: 0.6220\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.0431 - accuracy: 0.6382 - val_loss: 0.9702 - val_accuracy: 0.6624\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.9684 - accuracy: 0.6662 - val_loss: 0.9526 - val_accuracy: 0.6762\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.9099 - accuracy: 0.6873 - val_loss: 0.9356 - val_accuracy: 0.6764\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.8440 - accuracy: 0.7090 - val_loss: 0.8492 - val_accuracy: 0.7110\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.8008 - accuracy: 0.7255 - val_loss: 0.8994 - val_accuracy: 0.6907\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.7528 - accuracy: 0.7445 - val_loss: 0.7756 - val_accuracy: 0.7337\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.7113 - accuracy: 0.7567 - val_loss: 0.7782 - val_accuracy: 0.7297\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.6755 - accuracy: 0.7684 - val_loss: 0.7310 - val_accuracy: 0.7541\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.6407 - accuracy: 0.7787 - val_loss: 0.7530 - val_accuracy: 0.7456\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.6133 - accuracy: 0.7888 - val_loss: 0.8093 - val_accuracy: 0.7352\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.5851 - accuracy: 0.8001 - val_loss: 0.7035 - val_accuracy: 0.7628\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.5570 - accuracy: 0.8079 - val_loss: 0.7966 - val_accuracy: 0.7383\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.5331 - accuracy: 0.8182 - val_loss: 0.7389 - val_accuracy: 0.7570\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4920 - accuracy: 0.8289 - val_loss: 0.7950 - val_accuracy: 0.7426\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.4811 - accuracy: 0.8339 - val_loss: 0.7532 - val_accuracy: 0.7520\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.4502 - accuracy: 0.8419 - val_loss: 0.7344 - val_accuracy: 0.7666\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.4244 - accuracy: 0.8514 - val_loss: 0.8119 - val_accuracy: 0.7502\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4087 - accuracy: 0.8565 - val_loss: 0.7401 - val_accuracy: 0.7680\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.3823 - accuracy: 0.8667 - val_loss: 0.8157 - val_accuracy: 0.7535\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.3639 - accuracy: 0.8731 - val_loss: 0.7771 - val_accuracy: 0.7662\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.3415 - accuracy: 0.8792 - val_loss: 0.8788 - val_accuracy: 0.7503\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.3278 - accuracy: 0.8837 - val_loss: 0.9160 - val_accuracy: 0.7384\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.2986 - accuracy: 0.8926 - val_loss: 1.0336 - val_accuracy: 0.7319\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.2993 - accuracy: 0.8921 - val_loss: 0.8647 - val_accuracy: 0.7652\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2608 - accuracy: 0.9077 - val_loss: 0.9039 - val_accuracy: 0.7619\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2482 - accuracy: 0.9123 - val_loss: 1.0257 - val_accuracy: 0.7398\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2331 - accuracy: 0.9169 - val_loss: 1.0101 - val_accuracy: 0.7491\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.2360 - accuracy: 0.9153 - val_loss: 0.9408 - val_accuracy: 0.7615\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.1949 - accuracy: 0.9304 - val_loss: 1.1803 - val_accuracy: 0.7415\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1912 - accuracy: 0.9317 - val_loss: 1.0800 - val_accuracy: 0.7515\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.1843 - accuracy: 0.9343 - val_loss: 1.0749 - val_accuracy: 0.7561\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.1768 - accuracy: 0.9367 - val_loss: 1.1038 - val_accuracy: 0.7546\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1614 - accuracy: 0.9428 - val_loss: 1.1048 - val_accuracy: 0.7542\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1404 - accuracy: 0.9505 - val_loss: 1.2017 - val_accuracy: 0.7538\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1565 - accuracy: 0.9455 - val_loss: 1.3901 - val_accuracy: 0.7345\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1345 - accuracy: 0.9519 - val_loss: 1.2792 - val_accuracy: 0.7519\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1244 - accuracy: 0.9556 - val_loss: 1.1670 - val_accuracy: 0.7625\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1251 - accuracy: 0.9562 - val_loss: 1.2743 - val_accuracy: 0.7541\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0952 - accuracy: 0.9665 - val_loss: 1.3980 - val_accuracy: 0.7410\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1044 - accuracy: 0.9624 - val_loss: 1.3828 - val_accuracy: 0.7484\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0933 - accuracy: 0.9679 - val_loss: 1.3607 - val_accuracy: 0.7585\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0981 - accuracy: 0.9659 - val_loss: 1.4466 - val_accuracy: 0.7556\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0918 - accuracy: 0.9687 - val_loss: 1.3311 - val_accuracy: 0.7621\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0986 - accuracy: 0.9665 - val_loss: 1.5783 - val_accuracy: 0.7441\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0748 - accuracy: 0.9739 - val_loss: 1.4660 - val_accuracy: 0.7547\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0605 - accuracy: 0.9797 - val_loss: 1.4244 - val_accuracy: 0.7645\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 1.5566 - val_accuracy: 0.7502\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0577 - accuracy: 0.9800 - val_loss: 1.6568 - val_accuracy: 0.7527\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0631 - accuracy: 0.9779 - val_loss: 1.5565 - val_accuracy: 0.7573\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0494 - accuracy: 0.9833 - val_loss: 1.5768 - val_accuracy: 0.7547\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0418 - accuracy: 0.9859 - val_loss: 1.5964 - val_accuracy: 0.7622\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 1.7418 - val_accuracy: 0.7531\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0985 - accuracy: 0.9670 - val_loss: 1.6836 - val_accuracy: 0.7444\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0610 - accuracy: 0.9793 - val_loss: 1.5524 - val_accuracy: 0.7603\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0381 - accuracy: 0.9871 - val_loss: 1.6295 - val_accuracy: 0.7660\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 1.6276 - val_accuracy: 0.7637\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 1.7247 - val_accuracy: 0.7598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGP4SQfciYey",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` and no data augmentation (groups of 16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ4zqGihia2J",
        "colab_type": "code",
        "outputId": "56de6bf2-9ba5-46f1-d1b0-5a4c20a9ebbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"EvoNorm2dS0-no-aug-group16\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=16)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-no-aug-group16\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-no-aug-group16</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8308 - accuracy: 0.3224"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Layer EvoNorm2dS0 has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 16s 40ms/step - loss: 1.8308 - accuracy: 0.3224 - val_loss: 1.5047 - val_accuracy: 0.4589\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.3696 - accuracy: 0.5099 - val_loss: 1.2704 - val_accuracy: 0.5501\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.1897 - accuracy: 0.5844 - val_loss: 1.1100 - val_accuracy: 0.6219\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 1.0697 - accuracy: 0.6273 - val_loss: 1.0316 - val_accuracy: 0.6340\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.9876 - accuracy: 0.6610 - val_loss: 0.9818 - val_accuracy: 0.6625\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.9135 - accuracy: 0.6849 - val_loss: 0.9120 - val_accuracy: 0.6852\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.8565 - accuracy: 0.7054 - val_loss: 0.8661 - val_accuracy: 0.7071\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.8055 - accuracy: 0.7238 - val_loss: 0.9307 - val_accuracy: 0.6772\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.7593 - accuracy: 0.7414 - val_loss: 0.8080 - val_accuracy: 0.7272\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.7233 - accuracy: 0.7522 - val_loss: 0.8154 - val_accuracy: 0.7203\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.6910 - accuracy: 0.7623 - val_loss: 0.7436 - val_accuracy: 0.7469\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.6521 - accuracy: 0.7782 - val_loss: 0.7716 - val_accuracy: 0.7401\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.6269 - accuracy: 0.7852 - val_loss: 0.7922 - val_accuracy: 0.7426\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.5982 - accuracy: 0.7916 - val_loss: 0.7622 - val_accuracy: 0.7464\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.5690 - accuracy: 0.8046 - val_loss: 0.8275 - val_accuracy: 0.7289\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.5409 - accuracy: 0.8129 - val_loss: 0.7208 - val_accuracy: 0.7649\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.5127 - accuracy: 0.8237 - val_loss: 0.7555 - val_accuracy: 0.7604\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4805 - accuracy: 0.8328 - val_loss: 0.8156 - val_accuracy: 0.7405\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4548 - accuracy: 0.8409 - val_loss: 0.8149 - val_accuracy: 0.7524\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4209 - accuracy: 0.8534 - val_loss: 0.8674 - val_accuracy: 0.7380\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4194 - accuracy: 0.8528 - val_loss: 0.8024 - val_accuracy: 0.7564\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3843 - accuracy: 0.8656 - val_loss: 0.8719 - val_accuracy: 0.7476\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3650 - accuracy: 0.8715 - val_loss: 0.8248 - val_accuracy: 0.7601\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3477 - accuracy: 0.8783 - val_loss: 0.9150 - val_accuracy: 0.7394\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3432 - accuracy: 0.8778 - val_loss: 0.8559 - val_accuracy: 0.7510\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2934 - accuracy: 0.8974 - val_loss: 0.8805 - val_accuracy: 0.7656\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2790 - accuracy: 0.9009 - val_loss: 0.9485 - val_accuracy: 0.7477\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2725 - accuracy: 0.9033 - val_loss: 0.9574 - val_accuracy: 0.7493\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2610 - accuracy: 0.9076 - val_loss: 0.9759 - val_accuracy: 0.7516\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2329 - accuracy: 0.9169 - val_loss: 1.0856 - val_accuracy: 0.7454\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2326 - accuracy: 0.9181 - val_loss: 1.1407 - val_accuracy: 0.7268\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2074 - accuracy: 0.9264 - val_loss: 1.1730 - val_accuracy: 0.7406\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2032 - accuracy: 0.9271 - val_loss: 1.1161 - val_accuracy: 0.7424\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1802 - accuracy: 0.9361 - val_loss: 1.1163 - val_accuracy: 0.7502\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.1711 - accuracy: 0.9386 - val_loss: 1.1350 - val_accuracy: 0.7495\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1710 - accuracy: 0.9390 - val_loss: 1.1919 - val_accuracy: 0.7471\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1463 - accuracy: 0.9482 - val_loss: 1.2214 - val_accuracy: 0.7509\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1370 - accuracy: 0.9516 - val_loss: 1.2564 - val_accuracy: 0.7507\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.1358 - accuracy: 0.9515 - val_loss: 1.3163 - val_accuracy: 0.7471\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1242 - accuracy: 0.9557 - val_loss: 1.2331 - val_accuracy: 0.7571\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1112 - accuracy: 0.9612 - val_loss: 1.4364 - val_accuracy: 0.7453\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1367 - accuracy: 0.9515 - val_loss: 1.3350 - val_accuracy: 0.7472\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1015 - accuracy: 0.9648 - val_loss: 1.3640 - val_accuracy: 0.7523\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0893 - accuracy: 0.9690 - val_loss: 1.4980 - val_accuracy: 0.7459\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0872 - accuracy: 0.9695 - val_loss: 1.4470 - val_accuracy: 0.7459\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0785 - accuracy: 0.9721 - val_loss: 1.5161 - val_accuracy: 0.7574\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.0840 - accuracy: 0.9706 - val_loss: 1.4866 - val_accuracy: 0.7561\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0836 - accuracy: 0.9715 - val_loss: 1.5819 - val_accuracy: 0.7425\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0707 - accuracy: 0.9755 - val_loss: 1.4853 - val_accuracy: 0.7540\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0511 - accuracy: 0.9829 - val_loss: 1.8212 - val_accuracy: 0.7397\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0642 - accuracy: 0.9786 - val_loss: 1.6260 - val_accuracy: 0.7591\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0682 - accuracy: 0.9766 - val_loss: 1.8122 - val_accuracy: 0.7410\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0634 - accuracy: 0.9780 - val_loss: 1.6489 - val_accuracy: 0.7486\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0487 - accuracy: 0.9828 - val_loss: 1.6926 - val_accuracy: 0.7545\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 1.7198 - val_accuracy: 0.7561\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 1.7313 - val_accuracy: 0.7572\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 1.9455 - val_accuracy: 0.7506\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 1.8152 - val_accuracy: 0.7565\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0495 - accuracy: 0.9827 - val_loss: 1.8210 - val_accuracy: 0.7507\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 1.9373 - val_accuracy: 0.7477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6nZcE2hSWio",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` with no data augmentation (groups of 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYJEL7JHSYdq",
        "colab_type": "code",
        "outputId": "5462b019-33d0-434e-db11-d26d5b644cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"EvoNorm2dS0-no-aug-group32\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=32)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-no-aug-group32\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-no-aug-group32</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 16s 40ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 15s 40ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuMJziXASq1L",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` with data augmentation (groups of 8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6VWleEnSqU3",
        "colab_type": "code",
        "outputId": "1a478edf-04ff-436c-8157-7731a77b5778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"EvoNorm2dS0-data-aug-group8\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=8)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-data-aug-group8\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-data-aug-group8</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1044 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 11s 29ms/step - loss: nan - accuracy: 0.0969 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1051 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0971 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1033 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0954 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1041 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 11s 29ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1011 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0958 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1046 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 11s 29ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 11s 29ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 11s 29ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1036 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPX48vJaiGyq",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` with data augmentation (groups of 16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blWXvfkSiKo2",
        "colab_type": "code",
        "outputId": "c933b413-9a56-4d6c-cc27-5810edd4b683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"EvoNorm2dS0-data-aug-group16\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=16)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-data-aug-group16\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-data-aug-group16</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1023 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: nan - accuracy: 0.1025 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0944 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0951 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1023 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1061 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0946 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1044 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1019 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1043 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0957 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0952 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1020 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0969 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0972 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1049 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFCGEgXCTMCd",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` with data augmentation (groups of 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jakxsd_hTGG6",
        "colab_type": "code",
        "outputId": "f29871d0-7a82-4288-866b-20c4a4f7ea5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"EvoNorm2dS0-data-aug-group32\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=32)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-data-aug-group32\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/EvoNorm2dS0-data-aug-group32</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1027 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0967 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0949 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1059 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1037 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1015 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0995 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0953 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1035 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1018 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0972 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0935 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1049 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1027 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: nan - accuracy: 0.0961 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 12s 30ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}