{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini_Inception_BN_ReLU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/EvoNorms-in-TensorFlow-2/blob/master/Mini_Inception_BN_ReLU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIDRpbh_NYi1",
        "colab_type": "code",
        "outputId": "137e689b-6641-43c9-ebdc-c6fb82ca093e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Which GPU? \n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 19 03:34:26 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-Rvt-ZwXEi4",
        "colab_type": "code",
        "outputId": "7495daad-86dc-49fb-e8aa-71825b51563d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtcnpdbgZavs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other imports\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoN2l9PcNgxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the random seeds\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tzaJSLWNhjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5fa7780b-9420-4294-8a8c-2d5409f34e7b"
      },
      "source": [
        "# Set up wandb for easy experiment tracking\n",
        "!pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 4.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 24.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 39.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVMZEEWBZ8jf",
        "colab_type": "code",
        "outputId": "bfcc033c-9f4b-4252-ffc1-cce60a91887a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Load and preprocess CIFAR10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255.\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgP6ZIWVXQXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementation comes from http://pyimg.co/mac01\n",
        "def minigooglenet_functional(width, height, depth, classes):\n",
        "\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\n",
        "\t\t# define a CONV => BN => RELU pattern\n",
        "\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n",
        "\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef inception_module(x, numK1x1, numK3x3, chanDim):\n",
        "\t\t# define two CONV modules, then concatenate across the\n",
        "\t\t# channel dimension\n",
        "\t\tconv_1x1 = conv_module(x, numK1x1, 1, 1, (1, 1), chanDim)\n",
        "\t\tconv_3x3 = conv_module(x, numK3x3, 3, 3, (1, 1), chanDim)\n",
        "\t\tx = concatenate([conv_1x1, conv_3x3], axis=chanDim)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef downsample_module(x, K, chanDim):\n",
        "\t\t# define the CONV module and POOL, then concatenate\n",
        "\t\t# across the channel dimensions\n",
        "\t\tconv_3x3 = conv_module(x, K, 3, 3, (2, 2), chanDim,\n",
        "\t\t\tpadding=\"valid\")\n",
        "\t\tpool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\t\tx = concatenate([conv_3x3, pool], axis=chanDim)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\t# initialize the input shape to be \"channels last\" and the\n",
        "\t# channels dimension itself\n",
        "\tinputShape = (height, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\t# define the model input and first CONV module\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = conv_module(inputs, 96, 3, 3, (1, 1), chanDim)\n",
        "\n",
        "\t# two Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 32, 32, chanDim)\n",
        "\tx = inception_module(x, 32, 48, chanDim)\n",
        "\tx = downsample_module(x, 80, chanDim)\n",
        "\n",
        "\t# four Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 112, 48, chanDim)\n",
        "\tx = inception_module(x, 96, 64, chanDim)\n",
        "\tx = inception_module(x, 80, 80, chanDim)\n",
        "\tx = inception_module(x, 48, 96, chanDim)\n",
        "\tx = downsample_module(x, 96, chanDim)\n",
        "\n",
        "\t# two Inception modules followed by global POOL and dropout\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = AveragePooling2D((7, 7))(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\n",
        "\t# softmax classifier\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(classes)(x)\n",
        "\tx = Activation(\"softmax\")(x)\n",
        "\n",
        "\t# create the model\n",
        "\tmodel = Model(inputs, x, name=\"minigooglenet\")\n",
        "\n",
        "\t# return the constructed network architecture\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGDaupx6a5TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparams\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy9af9BYNtU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import wandb's Keras callback\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NkaZ7H2ZsmM",
        "colab_type": "code",
        "outputId": "652070d0-c6f0-48ea-846e-99feefa84ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"bn-relu-adam-no-aug\")\n",
        "\n",
        "# Compile and train this model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/bn-relu-adam-no-aug\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/bn-relu-adam-no-aug</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 19s 49ms/step - loss: 1.2531 - accuracy: 0.5490 - val_loss: 1.5977 - val_accuracy: 0.4144\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.7932 - accuracy: 0.7216 - val_loss: 1.1352 - val_accuracy: 0.6352\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.6114 - accuracy: 0.7885 - val_loss: 0.7932 - val_accuracy: 0.7158\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.4920 - accuracy: 0.8302 - val_loss: 0.8799 - val_accuracy: 0.7032\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.4119 - accuracy: 0.8583 - val_loss: 0.8826 - val_accuracy: 0.7272\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.3385 - accuracy: 0.8828 - val_loss: 0.9387 - val_accuracy: 0.7149\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.2816 - accuracy: 0.9023 - val_loss: 0.7375 - val_accuracy: 0.7729\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.2340 - accuracy: 0.9171 - val_loss: 0.9121 - val_accuracy: 0.7290\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.1950 - accuracy: 0.9309 - val_loss: 1.5493 - val_accuracy: 0.6553\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.1551 - accuracy: 0.9464 - val_loss: 0.8638 - val_accuracy: 0.7837\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.1323 - accuracy: 0.9536 - val_loss: 1.1678 - val_accuracy: 0.7128\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.1061 - accuracy: 0.9632 - val_loss: 0.7333 - val_accuracy: 0.7981\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0923 - accuracy: 0.9677 - val_loss: 0.7683 - val_accuracy: 0.8076\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0786 - accuracy: 0.9738 - val_loss: 0.9225 - val_accuracy: 0.7779\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0861 - accuracy: 0.9708 - val_loss: 0.9585 - val_accuracy: 0.7917\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0657 - accuracy: 0.9771 - val_loss: 1.0770 - val_accuracy: 0.7694\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0674 - accuracy: 0.9771 - val_loss: 1.1623 - val_accuracy: 0.7665\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0606 - accuracy: 0.9793 - val_loss: 1.1226 - val_accuracy: 0.7617\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0574 - accuracy: 0.9804 - val_loss: 1.0136 - val_accuracy: 0.8006\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0459 - accuracy: 0.9846 - val_loss: 1.0616 - val_accuracy: 0.7913\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 1.1115 - val_accuracy: 0.8078\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0493 - accuracy: 0.9826 - val_loss: 0.9155 - val_accuracy: 0.8124\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 1.0185 - val_accuracy: 0.7997\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0428 - accuracy: 0.9856 - val_loss: 1.1612 - val_accuracy: 0.7686\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0407 - accuracy: 0.9860 - val_loss: 0.9120 - val_accuracy: 0.8138\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0404 - accuracy: 0.9868 - val_loss: 1.2297 - val_accuracy: 0.7720\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0396 - accuracy: 0.9866 - val_loss: 0.9594 - val_accuracy: 0.8097\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.8903 - val_accuracy: 0.8043\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0369 - accuracy: 0.9876 - val_loss: 0.9340 - val_accuracy: 0.8228\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 1.1757 - val_accuracy: 0.8170\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 1.2818 - val_accuracy: 0.7673\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0306 - accuracy: 0.9891 - val_loss: 0.9718 - val_accuracy: 0.8067\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0373 - accuracy: 0.9871 - val_loss: 1.1421 - val_accuracy: 0.8001\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0275 - accuracy: 0.9903 - val_loss: 0.9092 - val_accuracy: 0.8359\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 1.2927 - val_accuracy: 0.7838\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.9557 - val_accuracy: 0.8230\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.9252 - val_accuracy: 0.8415\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 1.2093 - val_accuracy: 0.7799\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 1.0160 - val_accuracy: 0.8163\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0297 - accuracy: 0.9894 - val_loss: 1.1843 - val_accuracy: 0.8097\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.9955 - val_accuracy: 0.8299\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 1.1153 - val_accuracy: 0.8250\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 1.1991 - val_accuracy: 0.7983\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 1.1271 - val_accuracy: 0.8263\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.8798 - val_accuracy: 0.8462\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 1.3462 - val_accuracy: 0.7931\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0291 - accuracy: 0.9899 - val_loss: 1.1506 - val_accuracy: 0.7971\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 1.2921 - val_accuracy: 0.7984\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 1.4424 - val_accuracy: 0.7739\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 1.1205 - val_accuracy: 0.8127\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 1.0033 - val_accuracy: 0.8351\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 1.1575 - val_accuracy: 0.8122\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.8696 - val_accuracy: 0.8491\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.8198 - val_accuracy: 0.8492\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.8305 - val_accuracy: 0.8471\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 1.0730 - val_accuracy: 0.8203\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 0.9114 - val_accuracy: 0.8416\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.9617 - val_accuracy: 0.8385\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 1.0058 - val_accuracy: 0.8323\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 1.1883 - val_accuracy: 0.8091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg61Q51Tdten",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try one-hot encoding the labels and then see\n",
        "y_train_ohe = tf.keras.utils.to_categorical(y_train)\n",
        "y_test_ohe = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyDjh7f9eNs0",
        "colab_type": "code",
        "outputId": "c2ff5784-6307-4af3-9a79-92db55932f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"bn-relu-adam-no-aug-ohe\")\n",
        "\n",
        "# Compile and train this model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/bn-relu-adam-no-aug-ohe\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/bn-relu-adam-no-aug-ohe</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 1.2473 - accuracy: 0.5482 - val_loss: 2.0603 - val_accuracy: 0.3314\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.7707 - accuracy: 0.7320 - val_loss: 1.2857 - val_accuracy: 0.5950\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.5936 - accuracy: 0.7966 - val_loss: 1.2780 - val_accuracy: 0.5845\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.4791 - accuracy: 0.8333 - val_loss: 0.9049 - val_accuracy: 0.7038\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.4018 - accuracy: 0.8623 - val_loss: 1.0725 - val_accuracy: 0.6950\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.3354 - accuracy: 0.8843 - val_loss: 0.8662 - val_accuracy: 0.7507\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.2745 - accuracy: 0.9051 - val_loss: 0.9970 - val_accuracy: 0.7202\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.2273 - accuracy: 0.9217 - val_loss: 0.6420 - val_accuracy: 0.7940\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.1881 - accuracy: 0.9343 - val_loss: 0.9226 - val_accuracy: 0.7380\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.1504 - accuracy: 0.9477 - val_loss: 0.9688 - val_accuracy: 0.7789\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.1334 - accuracy: 0.9533 - val_loss: 0.8999 - val_accuracy: 0.7659\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.1070 - accuracy: 0.9638 - val_loss: 1.1199 - val_accuracy: 0.7382\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0952 - accuracy: 0.9674 - val_loss: 0.9482 - val_accuracy: 0.7712\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0816 - accuracy: 0.9718 - val_loss: 0.7381 - val_accuracy: 0.8179\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0757 - accuracy: 0.9741 - val_loss: 0.7127 - val_accuracy: 0.8272\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 1.0402 - val_accuracy: 0.7747\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0681 - accuracy: 0.9766 - val_loss: 1.7721 - val_accuracy: 0.7031\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.8345 - val_accuracy: 0.8158\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0538 - accuracy: 0.9812 - val_loss: 0.8987 - val_accuracy: 0.8113\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0557 - accuracy: 0.9802 - val_loss: 0.7706 - val_accuracy: 0.8310\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0468 - accuracy: 0.9836 - val_loss: 0.8479 - val_accuracy: 0.8111\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.9618 - val_accuracy: 0.8012\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.9793 - val_accuracy: 0.7911\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 3.4746 - val_accuracy: 0.6262\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0451 - accuracy: 0.9845 - val_loss: 1.8032 - val_accuracy: 0.7047\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.9130 - val_accuracy: 0.8096\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 1.0060 - val_accuracy: 0.8065\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0409 - accuracy: 0.9866 - val_loss: 1.2214 - val_accuracy: 0.7927\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0385 - accuracy: 0.9867 - val_loss: 1.0545 - val_accuracy: 0.7973\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.9129 - val_accuracy: 0.8298\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0330 - accuracy: 0.9881 - val_loss: 1.4133 - val_accuracy: 0.7694\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 1.0017 - val_accuracy: 0.8170\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 1.1902 - val_accuracy: 0.7952\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0324 - accuracy: 0.9891 - val_loss: 0.7767 - val_accuracy: 0.8421\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.8910 - val_accuracy: 0.8202\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 0.8300 - val_accuracy: 0.8452\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 1.1423 - val_accuracy: 0.8119\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 1.0967 - val_accuracy: 0.7868\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 1.0024 - val_accuracy: 0.8184\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 1.0599 - val_accuracy: 0.8205\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0321 - accuracy: 0.9894 - val_loss: 0.8803 - val_accuracy: 0.8309\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 1.1411 - val_accuracy: 0.8114\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 1.1147 - val_accuracy: 0.8155\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 1.1911 - val_accuracy: 0.8145\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.9588 - val_accuracy: 0.8364\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 1.1211 - val_accuracy: 0.8204\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 1.0135 - val_accuracy: 0.8293\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.8183 - val_accuracy: 0.8482\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 1.0449 - val_accuracy: 0.8397\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.9605 - val_accuracy: 0.8270\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.9306 - val_accuracy: 0.8409\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.8525 - val_accuracy: 0.8399\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.9820 - val_accuracy: 0.8469\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.9521 - val_accuracy: 0.8333\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 1.2679 - val_accuracy: 0.8125\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 1.0762 - val_accuracy: 0.8269\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 1.0944 - val_accuracy: 0.8166\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.8880 - val_accuracy: 0.8525\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.1278 - val_accuracy: 0.8186\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 18s 45ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.8875 - val_accuracy: 0.8398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJqY9yadgpka",
        "colab_type": "code",
        "outputId": "13d075a4-3787-4673-c9a8-55151326ba3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"bn-relu-sgd-no-aug-one-hot\")\n",
        "\n",
        "# Let's try changing the optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train this model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/bn-relu-sgd-no-aug-one-hot\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/bn-relu-sgd-no-aug-one-hot</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 1.4166 - accuracy: 0.4820 - val_loss: 1.8228 - val_accuracy: 0.3759\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.9686 - accuracy: 0.6537 - val_loss: 1.2731 - val_accuracy: 0.5557\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.7899 - accuracy: 0.7201 - val_loss: 0.9378 - val_accuracy: 0.6669\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.6583 - accuracy: 0.7701 - val_loss: 0.9670 - val_accuracy: 0.6682\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.5654 - accuracy: 0.8034 - val_loss: 0.9329 - val_accuracy: 0.6865\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.4810 - accuracy: 0.8329 - val_loss: 1.0262 - val_accuracy: 0.6789\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.4101 - accuracy: 0.8600 - val_loss: 0.9762 - val_accuracy: 0.7061\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.3464 - accuracy: 0.8812 - val_loss: 0.8564 - val_accuracy: 0.7286\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.2893 - accuracy: 0.9015 - val_loss: 0.9126 - val_accuracy: 0.7315\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.2335 - accuracy: 0.9199 - val_loss: 1.2708 - val_accuracy: 0.6775\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.1841 - accuracy: 0.9390 - val_loss: 1.3177 - val_accuracy: 0.6901\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.1439 - accuracy: 0.9529 - val_loss: 0.9612 - val_accuracy: 0.7464\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.1119 - accuracy: 0.9646 - val_loss: 0.8327 - val_accuracy: 0.7783\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0868 - accuracy: 0.9727 - val_loss: 0.8496 - val_accuracy: 0.7742\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0626 - accuracy: 0.9820 - val_loss: 1.0945 - val_accuracy: 0.7469\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0483 - accuracy: 0.9871 - val_loss: 0.8550 - val_accuracy: 0.7832\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0377 - accuracy: 0.9906 - val_loss: 0.7466 - val_accuracy: 0.8057\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0289 - accuracy: 0.9934 - val_loss: 0.7567 - val_accuracy: 0.8106\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0187 - accuracy: 0.9969 - val_loss: 0.7610 - val_accuracy: 0.8206\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.7164 - val_accuracy: 0.8264\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0113 - accuracy: 0.9984 - val_loss: 0.7794 - val_accuracy: 0.8187\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.7007 - val_accuracy: 0.8318\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.7221 - val_accuracy: 0.8301\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.7077 - val_accuracy: 0.8308\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.7283 - val_accuracy: 0.8291\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.7974 - val_accuracy: 0.8209\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.6692 - val_accuracy: 0.8409\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.6781 - val_accuracy: 0.8409\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.7355 - val_accuracy: 0.8299\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.7096 - val_accuracy: 0.8385\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.7096 - val_accuracy: 0.8404\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.6979 - val_accuracy: 0.8397\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.7500 - val_accuracy: 0.8366\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.6924 - val_accuracy: 0.8423\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.7201 - val_accuracy: 0.8406\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.7095 - val_accuracy: 0.8400\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.7276 - val_accuracy: 0.8397\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.7034 - val_accuracy: 0.8436\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8396\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.6987 - val_accuracy: 0.8429\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.7072 - val_accuracy: 0.8418\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8421\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8430\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.7081 - val_accuracy: 0.8431\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.8432\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.7139 - val_accuracy: 0.8430\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8425\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8425\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8421\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.7076 - val_accuracy: 0.8456\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.7088 - val_accuracy: 0.8445\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8430\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.7835 - val_accuracy: 0.8346\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.8434\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8437\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8423\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8405\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.7154 - val_accuracy: 0.8404\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8416\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B3-oGcpjOYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try with data augmentation\n",
        "aug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=18, \n",
        "    zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, \n",
        "    shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiFkHoZmjcJ-",
        "colab_type": "code",
        "outputId": "202508e4-93eb-4ebd-8d21-1f6edfdf3069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"EvoNorm-TensorFlow2\", id=\"bn-relu-sgd-aug-ohe\")\n",
        "\n",
        "# Let's try changing the optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train this model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/bn-relu-sgd-aug-ohe\" target=\"_blank\">https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/runs/bn-relu-sgd-aug-ohe</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 10s 27ms/step - loss: 1.8879 - accuracy: 0.3054 - val_loss: 2.2616 - val_accuracy: 0.2069\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.5720 - accuracy: 0.4274 - val_loss: 1.7422 - val_accuracy: 0.3926\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.4400 - accuracy: 0.4759 - val_loss: 1.5125 - val_accuracy: 0.4727\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.3493 - accuracy: 0.5150 - val_loss: 1.2899 - val_accuracy: 0.5461\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.2495 - accuracy: 0.5569 - val_loss: 1.3680 - val_accuracy: 0.5353\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.1991 - accuracy: 0.5744 - val_loss: 1.3477 - val_accuracy: 0.5596\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.1538 - accuracy: 0.5859 - val_loss: 1.3506 - val_accuracy: 0.5480\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.0909 - accuracy: 0.6176 - val_loss: 1.3797 - val_accuracy: 0.5462\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.0438 - accuracy: 0.6362 - val_loss: 1.1906 - val_accuracy: 0.5939\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 1.0199 - accuracy: 0.6438 - val_loss: 1.0675 - val_accuracy: 0.6345\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.9584 - accuracy: 0.6675 - val_loss: 1.4118 - val_accuracy: 0.5790\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.9453 - accuracy: 0.6685 - val_loss: 1.1159 - val_accuracy: 0.6344\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.9107 - accuracy: 0.6812 - val_loss: 1.2887 - val_accuracy: 0.6048\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.8884 - accuracy: 0.6930 - val_loss: 1.1085 - val_accuracy: 0.6541\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.8695 - accuracy: 0.7002 - val_loss: 1.0657 - val_accuracy: 0.6700\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.8431 - accuracy: 0.7115 - val_loss: 0.9261 - val_accuracy: 0.7096\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.8150 - accuracy: 0.7145 - val_loss: 0.8968 - val_accuracy: 0.7081\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.8024 - accuracy: 0.7225 - val_loss: 0.7182 - val_accuracy: 0.7537\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.7970 - accuracy: 0.7276 - val_loss: 0.8998 - val_accuracy: 0.7192\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.7881 - accuracy: 0.7259 - val_loss: 0.7477 - val_accuracy: 0.7496\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.7622 - accuracy: 0.7402 - val_loss: 0.8894 - val_accuracy: 0.7152\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.7485 - accuracy: 0.7410 - val_loss: 0.9004 - val_accuracy: 0.7197\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.7409 - accuracy: 0.7472 - val_loss: 0.7694 - val_accuracy: 0.7456\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.7162 - accuracy: 0.7525 - val_loss: 0.6896 - val_accuracy: 0.7682\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.6963 - accuracy: 0.7648 - val_loss: 0.7515 - val_accuracy: 0.7462\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.6978 - accuracy: 0.7582 - val_loss: 0.7785 - val_accuracy: 0.7521\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.6773 - accuracy: 0.7674 - val_loss: 0.6998 - val_accuracy: 0.7727\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.6813 - accuracy: 0.7646 - val_loss: 0.8024 - val_accuracy: 0.7274\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.6541 - accuracy: 0.7739 - val_loss: 0.7291 - val_accuracy: 0.7623\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.6553 - accuracy: 0.7791 - val_loss: 0.5874 - val_accuracy: 0.8012\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.6479 - accuracy: 0.7840 - val_loss: 0.6421 - val_accuracy: 0.7889\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.6502 - accuracy: 0.7807 - val_loss: 0.5600 - val_accuracy: 0.8140\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.6206 - accuracy: 0.7889 - val_loss: 0.6098 - val_accuracy: 0.8034\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.6226 - accuracy: 0.7883 - val_loss: 0.7314 - val_accuracy: 0.7735\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.6143 - accuracy: 0.7926 - val_loss: 0.8217 - val_accuracy: 0.7563\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.6091 - accuracy: 0.7931 - val_loss: 0.5373 - val_accuracy: 0.8123\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.5736 - accuracy: 0.8032 - val_loss: 0.7510 - val_accuracy: 0.7690\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.5905 - accuracy: 0.7986 - val_loss: 0.7470 - val_accuracy: 0.7763\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5911 - accuracy: 0.7974 - val_loss: 0.6244 - val_accuracy: 0.7930\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.5743 - accuracy: 0.8057 - val_loss: 0.5639 - val_accuracy: 0.8151\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5621 - accuracy: 0.8066 - val_loss: 0.7813 - val_accuracy: 0.7779\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.5582 - accuracy: 0.8051 - val_loss: 0.5326 - val_accuracy: 0.8211\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5481 - accuracy: 0.8107 - val_loss: 0.7311 - val_accuracy: 0.7744\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.5547 - accuracy: 0.8111 - val_loss: 0.6830 - val_accuracy: 0.7867\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5402 - accuracy: 0.8167 - val_loss: 0.6207 - val_accuracy: 0.7980\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.5468 - accuracy: 0.8145 - val_loss: 0.6637 - val_accuracy: 0.7866\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.5416 - accuracy: 0.8158 - val_loss: 0.6514 - val_accuracy: 0.7921\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5345 - accuracy: 0.8197 - val_loss: 0.6837 - val_accuracy: 0.7949\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.5145 - accuracy: 0.8257 - val_loss: 0.6501 - val_accuracy: 0.7907\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5171 - accuracy: 0.8236 - val_loss: 0.5414 - val_accuracy: 0.8120\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5265 - accuracy: 0.8188 - val_loss: 0.6279 - val_accuracy: 0.8045\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5342 - accuracy: 0.8159 - val_loss: 0.6095 - val_accuracy: 0.8161\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: 0.5011 - accuracy: 0.8314 - val_loss: 0.5859 - val_accuracy: 0.8178\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.5027 - accuracy: 0.8292 - val_loss: 0.5304 - val_accuracy: 0.8288\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.4938 - accuracy: 0.8346 - val_loss: 0.6458 - val_accuracy: 0.8014\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.5058 - accuracy: 0.8275 - val_loss: 0.5983 - val_accuracy: 0.8033\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.4781 - accuracy: 0.8372 - val_loss: 0.5729 - val_accuracy: 0.8167\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 10s 25ms/step - loss: 0.4904 - accuracy: 0.8304 - val_loss: 0.4612 - val_accuracy: 0.8434\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.4765 - accuracy: 0.8384 - val_loss: 0.4863 - val_accuracy: 0.8392\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 10s 24ms/step - loss: 0.4908 - accuracy: 0.8340 - val_loss: 0.5323 - val_accuracy: 0.8238\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}