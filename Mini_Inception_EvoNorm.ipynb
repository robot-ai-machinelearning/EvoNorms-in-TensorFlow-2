{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini_Inception_EvoNorm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoqFk4di90OUcNEEylFwPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/EvoNorms-in-TensorFlow-2/blob/master/Mini_Inception_EvoNorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vov59PhnHH5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "cd80d229-a8c3-4918-ff2a-761552a8a92d"
      },
      "source": [
        "# Which GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 18 07:53:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chf8mjl60M-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MszMKRN0nti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other imports\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DyzD6hk0rjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the random seeds\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wOz0xzLF8zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up wandb for easy experiment tracking\n",
        "!pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssVHc5nh0w0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8d766c2b-9e3c-4921-c26b-d80ce91a9df6"
      },
      "source": [
        "# Load and preprocess CIFAR10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255.\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udzb5ADxHYcM",
        "colab_type": "text"
      },
      "source": [
        "## `EvoNorm2dB0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PMnIekD0yTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference\n",
        "# https://github.com/lonePatient/EvoNorms_PyTorch/blob/master/models/normalization.py\n",
        "\n",
        "def instance_std(x, eps=1e-5):\n",
        "\t# https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
        "\t_, var = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
        "\treturn tf.sqrt(var + eps)\n",
        "\n",
        "class EvoNorm2dB0(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, in_channels, nonlinear=True, momentum=0.9,\n",
        "\t\teps=1e-5):\n",
        "\t\tsuper(EvoNorm2dB0, self).__init__()\n",
        "\t\tself.nonlinear = nonlinear\n",
        "\t\tself.momentum = momentum\n",
        "\t\tself.eps = eps\n",
        "\t\tself.running_var = tf.ones((1, in_channels, 1, 1))\n",
        "\n",
        "\t\tdef build(self):\n",
        "\t\t\tself.gamma = self.add_variable(\"gamma\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, self.in_channels, 1, 1),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Ones())\n",
        "\t\t\tself.beta = self.add_variable(\"beta\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, self.in_channels, 1, 1),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Zeros())\n",
        "\t\t\tif self.nonlinear:\n",
        "\t\t\t\tself.v = self.add_variable(\"v\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, self.in_channels, 1, 1),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Ones())\n",
        "\n",
        "\n",
        "\t\tdef call(self, x):\n",
        "\t\t\tN, H, W, C = tf.shape(x)\n",
        "\n",
        "\t\t\tif self.training:\n",
        "\t\t\t\tx1 = tf.transpose(x, [3, 0, 1, 2])\n",
        "\t\t\t\tx1 = tf.reshape(x1, (C, -1))\n",
        "\t\t\t\tvar = tf.math.reduce_std(x1, axis=1)\n",
        "\t\t\t\tvar = tf.reshape(var, (1, C, 1, 1))\n",
        "\t\t\t\tself.running_var = self.momentum * self.running_var + (1 - self.momentum) * var\n",
        "\t\t\telse:\n",
        "\t\t\t\tvar = self.running_var\n",
        "\n",
        "\t\t\tif self.nonlinear:\n",
        "\t\t\t\tden = tf.math.maximum(tf.sqrt(var+self.eps), self.v * x + instance_std(x))\n",
        "\t\t\t\treturn x / den * self.gamma + self.beta\n",
        "\t\t\telse:\n",
        "\t\t\t\treturn x * self.gamma + self.beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "katzf-j4Hb3-",
        "colab_type": "text"
      },
      "source": [
        "## `EvoNorm2dS0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPpctYba05Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference\n",
        "# https://github.com/lonePatient/EvoNorms_PyTorch/blob/master/models/normalization.py\n",
        "\n",
        "def group_std(x, groups=32, eps=1e-5):\n",
        "\tN, H, W, C = tf.shape(x)\n",
        "\tx = tf.reshape(x, [N, H, W, groups, C // groups])\n",
        "\t_, var = tf.nn.moments(x, [1, 2, 4], keepdims=True)\n",
        "\tstd = tf.sqrt(var + eps)\n",
        "\tstd = tf.broadcast_to(std, x.shape)\n",
        "\treturn tf.reshape(std, (N, H, W, C))\n",
        "\n",
        "class EvoNorm2dS0(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, in_channels, groups=32, nonlinear=True):\n",
        "\t\tsuper(EvoNorm2dS0, self).__init__()\n",
        "\t\tself.nonlinear = nonlinear\n",
        "\t\tself.groups = groups\n",
        "\n",
        "\t\tdef build(self):\n",
        "\t\t\tself.gamma = self.add_variable(\"gamma\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, self.in_channels, 1, 1),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Ones())\n",
        "\t\t\tself.beta = self.add_variable(\"beta\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, self.in_channels, 1, 1),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Zeros())\n",
        "\t\t\tif self.nonlinear:\n",
        "\t\t\t\tself.v = self.add_variable(\"v\",\n",
        "\t\t\t\t\t\t\t\t\tshape=(1, self.in_channels, 1, 1),\n",
        "\t\t\t\t\t\t\t\t\tinitializer=tf.initializers.Ones())\n",
        "\n",
        "\n",
        "\t\tdef call(self, x):\n",
        "\t\t\tif self.nonlinear:\n",
        "\t\t\t\tnum = x * tf.nn.sigmoid(self.v * x)\n",
        "\t\t\t\treturn num / group_std(x) * self.gamma + self.beta\n",
        "\t\t\telse:\n",
        "\t\t\t\treturn x * self.gamma + self.beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngt39WlcSBH0",
        "colab_type": "text"
      },
      "source": [
        "## Mini Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgeN8DMD1Cze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementation comes from http://pyimg.co/mac01\n",
        "def minigooglenet_functional(width, height, depth, classes, norm=EvoNorm2dB0, groups=32):\n",
        "\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\n",
        "\t\t# define a CONV => EvoNorm pattern\n",
        "\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n",
        "\t\t\n",
        "\t\tif isinstance(norm, EvoNorm2dS0):\n",
        "\t\t\tlayer = norm(in_channels=K, groups=groups)\n",
        "\t\telse:\n",
        "\t\t\tlayer = norm(in_channels=K)\n",
        "\t\t\n",
        "\t\tx = layer(x)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef inception_module(x, numK1x1, numK3x3, chanDim):\n",
        "\t\t# define two CONV modules, then concatenate across the\n",
        "\t\t# channel dimension\n",
        "\t\tconv_1x1 = conv_module(x, numK1x1, 1, 1, (1, 1), chanDim)\n",
        "\t\tconv_3x3 = conv_module(x, numK3x3, 3, 3, (1, 1), chanDim)\n",
        "\t\tx = concatenate([conv_1x1, conv_3x3], axis=chanDim)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef downsample_module(x, K, chanDim):\n",
        "\t\t# define the CONV module and POOL, then concatenate\n",
        "\t\t# across the channel dimensions\n",
        "\t\tconv_3x3 = conv_module(x, K, 3, 3, (2, 2), chanDim,\n",
        "\t\t\tpadding=\"valid\")\n",
        "\t\tpool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\t\tx = concatenate([conv_3x3, pool], axis=chanDim)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\t# initialize the input shape to be \"channels last\" and the\n",
        "\t# channels dimension itself\n",
        "\tinputShape = (height, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\t# define the model input and first CONV module\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = conv_module(inputs, 96, 3, 3, (1, 1), chanDim)\n",
        "\n",
        "\t# two Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 32, 32, chanDim)\n",
        "\tx = inception_module(x, 32, 48, chanDim)\n",
        "\tx = downsample_module(x, 80, chanDim)\n",
        "\n",
        "\t# four Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 112, 48, chanDim)\n",
        "\tx = inception_module(x, 96, 64, chanDim)\n",
        "\tx = inception_module(x, 80, 80, chanDim)\n",
        "\tx = inception_module(x, 48, 96, chanDim)\n",
        "\tx = downsample_module(x, 96, chanDim)\n",
        "\n",
        "\t# two Inception modules followed by global POOL and dropout\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = AveragePooling2D((7, 7))(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\n",
        "\t# softmax classifier\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(classes)(x)\n",
        "\tx = Activation(\"softmax\")(x)\n",
        "\n",
        "\t# create the model\n",
        "\tmodel = Model(inputs, x, name=\"minigooglenet\")\n",
        "\n",
        "\t# return the constructed network architecture\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V99JZ-ip1n9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding of the labels\n",
        "y_train_ohe = tf.keras.utils.to_categorical(y_train)\n",
        "y_test_ohe = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDc4snWZ1yVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE=128\n",
        "EPOCHS=60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f4aTbCFGUn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import wandb's Keras callback\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qihy4IiF3DrS",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dB0` and no data agumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AiXZhQ5189_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7fc6fc48-a6d9-4e03-845c-96bddd28347d"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"EvoNorm2dB0-no-aug\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dB0-no-aug\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dB0-no-aug</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: nan - accuracy: 0.1016 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 15s 37ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85mX7gnbPn5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try with data augmentation\n",
        "aug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=18, \n",
        "    zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, \n",
        "    shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWIx1ixlMIw-",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dB0` and data agumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6jZNL60MLun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20c16015-bdbd-43d3-8b5a-e223f24d28a6"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"EvoNorm2dB0-data-aug\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dB0-data-aug\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dB0-data-aug</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: nan - accuracy: 0.1015 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1023 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0968 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0967 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1027 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1018 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0948 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1015 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1031 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0971 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1065 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0969 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyOaJyNMAkAe",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` and no data augmentation (groups of 8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db6InWQdAg1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "546cbed0-9948-4ed7-9d3e-b642a05aba44"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"EvoNorm2dS0-no-aug-group8\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=8)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-no-aug-group8\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-no-aug-group8</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7779 - accuracy: 0.3414"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Layer EvoNorm2dS0 has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 15s 38ms/step - loss: 1.7779 - accuracy: 0.3414 - val_loss: 1.4721 - val_accuracy: 0.4628\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.3366 - accuracy: 0.5260 - val_loss: 1.1769 - val_accuracy: 0.5871\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.1591 - accuracy: 0.5945 - val_loss: 1.1353 - val_accuracy: 0.6227\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.0426 - accuracy: 0.6385 - val_loss: 1.0279 - val_accuracy: 0.6353\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.9617 - accuracy: 0.6670 - val_loss: 0.9824 - val_accuracy: 0.6668\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.9011 - accuracy: 0.6914 - val_loss: 0.9299 - val_accuracy: 0.6816\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.8491 - accuracy: 0.7078 - val_loss: 0.8459 - val_accuracy: 0.7098\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.7907 - accuracy: 0.7294 - val_loss: 0.8800 - val_accuracy: 0.6980\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.7462 - accuracy: 0.7446 - val_loss: 0.7658 - val_accuracy: 0.7435\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.7067 - accuracy: 0.7583 - val_loss: 0.7959 - val_accuracy: 0.7231\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.6722 - accuracy: 0.7708 - val_loss: 0.7506 - val_accuracy: 0.7485\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6423 - accuracy: 0.7807 - val_loss: 0.7402 - val_accuracy: 0.7500\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6153 - accuracy: 0.7886 - val_loss: 0.7842 - val_accuracy: 0.7438\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5830 - accuracy: 0.8003 - val_loss: 0.7215 - val_accuracy: 0.7564\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5485 - accuracy: 0.8110 - val_loss: 0.7475 - val_accuracy: 0.7578\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5275 - accuracy: 0.8191 - val_loss: 0.7090 - val_accuracy: 0.7677\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4960 - accuracy: 0.8300 - val_loss: 0.7752 - val_accuracy: 0.7487\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4684 - accuracy: 0.8359 - val_loss: 0.7512 - val_accuracy: 0.7595\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4444 - accuracy: 0.8447 - val_loss: 0.7463 - val_accuracy: 0.7643\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4224 - accuracy: 0.8518 - val_loss: 0.8226 - val_accuracy: 0.7457\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4095 - accuracy: 0.8568 - val_loss: 0.7578 - val_accuracy: 0.7593\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3698 - accuracy: 0.8711 - val_loss: 0.8590 - val_accuracy: 0.7472\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3611 - accuracy: 0.8738 - val_loss: 0.8033 - val_accuracy: 0.7594\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3367 - accuracy: 0.8816 - val_loss: 0.8745 - val_accuracy: 0.7490\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3196 - accuracy: 0.8876 - val_loss: 0.9644 - val_accuracy: 0.7355\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2903 - accuracy: 0.8973 - val_loss: 1.0468 - val_accuracy: 0.7374\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3026 - accuracy: 0.8936 - val_loss: 0.9233 - val_accuracy: 0.7542\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2577 - accuracy: 0.9087 - val_loss: 0.9119 - val_accuracy: 0.7645\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2485 - accuracy: 0.9120 - val_loss: 0.9640 - val_accuracy: 0.7538\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2257 - accuracy: 0.9203 - val_loss: 1.0119 - val_accuracy: 0.7570\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2318 - accuracy: 0.9178 - val_loss: 1.0129 - val_accuracy: 0.7489\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2095 - accuracy: 0.9250 - val_loss: 0.9903 - val_accuracy: 0.7635\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1787 - accuracy: 0.9376 - val_loss: 1.0781 - val_accuracy: 0.7578\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1837 - accuracy: 0.9351 - val_loss: 1.0629 - val_accuracy: 0.7535\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1641 - accuracy: 0.9405 - val_loss: 1.1736 - val_accuracy: 0.7444\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1696 - accuracy: 0.9399 - val_loss: 1.1815 - val_accuracy: 0.7464\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1396 - accuracy: 0.9510 - val_loss: 1.1075 - val_accuracy: 0.7662\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1463 - accuracy: 0.9477 - val_loss: 1.1846 - val_accuracy: 0.7561\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1436 - accuracy: 0.9491 - val_loss: 1.2275 - val_accuracy: 0.7561\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1180 - accuracy: 0.9574 - val_loss: 1.1797 - val_accuracy: 0.7652\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1112 - accuracy: 0.9615 - val_loss: 1.3407 - val_accuracy: 0.7519\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0878 - accuracy: 0.9698 - val_loss: 1.2926 - val_accuracy: 0.7592\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0916 - accuracy: 0.9680 - val_loss: 1.4372 - val_accuracy: 0.7492\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1128 - accuracy: 0.9602 - val_loss: 1.4242 - val_accuracy: 0.7542\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0962 - accuracy: 0.9664 - val_loss: 1.4419 - val_accuracy: 0.7511\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0799 - accuracy: 0.9716 - val_loss: 1.3936 - val_accuracy: 0.7586\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0837 - accuracy: 0.9703 - val_loss: 1.4406 - val_accuracy: 0.7539\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0710 - accuracy: 0.9759 - val_loss: 1.4271 - val_accuracy: 0.7574\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0520 - accuracy: 0.9823 - val_loss: 1.5312 - val_accuracy: 0.7580\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 1.6337 - val_accuracy: 0.7537\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0534 - accuracy: 0.9819 - val_loss: 1.6134 - val_accuracy: 0.7587\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0623 - accuracy: 0.9781 - val_loss: 1.6329 - val_accuracy: 0.7503\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0990 - accuracy: 0.9664 - val_loss: 1.6542 - val_accuracy: 0.7429\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0757 - accuracy: 0.9746 - val_loss: 1.4997 - val_accuracy: 0.7607\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 1.6068 - val_accuracy: 0.7535\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 1.5934 - val_accuracy: 0.7643\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 1.6697 - val_accuracy: 0.7583\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 1.6972 - val_accuracy: 0.7628\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 1.7478 - val_accuracy: 0.7647\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 1.9165 - val_accuracy: 0.7562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGP4SQfciYey",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` and no data augmentation (groups of 16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ4zqGihia2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f0b18d6-74ae-4eb3-930c-4c9c05f9f3ea"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"EvoNorm2dS0-no-aug-group16\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=16)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-no-aug-group16\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-no-aug-group16</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7963 - accuracy: 0.3335"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Layer EvoNorm2dS0 has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 15s 39ms/step - loss: 1.7963 - accuracy: 0.3335 - val_loss: 1.5497 - val_accuracy: 0.4426\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.3618 - accuracy: 0.5136 - val_loss: 1.2394 - val_accuracy: 0.5645\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.1761 - accuracy: 0.5879 - val_loss: 1.1318 - val_accuracy: 0.6147\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.0636 - accuracy: 0.6292 - val_loss: 1.0735 - val_accuracy: 0.6058\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.9727 - accuracy: 0.6631 - val_loss: 0.9956 - val_accuracy: 0.6658\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.9202 - accuracy: 0.6832 - val_loss: 0.9226 - val_accuracy: 0.6781\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.8559 - accuracy: 0.7053 - val_loss: 0.8069 - val_accuracy: 0.7243\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.8116 - accuracy: 0.7240 - val_loss: 0.8790 - val_accuracy: 0.6980\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.7626 - accuracy: 0.7410 - val_loss: 0.8062 - val_accuracy: 0.7252\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.7218 - accuracy: 0.7529 - val_loss: 0.7874 - val_accuracy: 0.7311\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6955 - accuracy: 0.7602 - val_loss: 0.7924 - val_accuracy: 0.7251\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6595 - accuracy: 0.7731 - val_loss: 0.7409 - val_accuracy: 0.7484\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6235 - accuracy: 0.7863 - val_loss: 0.7568 - val_accuracy: 0.7469\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5915 - accuracy: 0.7973 - val_loss: 0.7552 - val_accuracy: 0.7461\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5707 - accuracy: 0.8031 - val_loss: 0.8412 - val_accuracy: 0.7260\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5456 - accuracy: 0.8113 - val_loss: 0.7151 - val_accuracy: 0.7604\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5133 - accuracy: 0.8220 - val_loss: 0.8080 - val_accuracy: 0.7426\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.4887 - accuracy: 0.8299 - val_loss: 0.7460 - val_accuracy: 0.7535\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4579 - accuracy: 0.8427 - val_loss: 0.7379 - val_accuracy: 0.7675\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4439 - accuracy: 0.8463 - val_loss: 0.9292 - val_accuracy: 0.7207\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4085 - accuracy: 0.8579 - val_loss: 0.7947 - val_accuracy: 0.7577\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3905 - accuracy: 0.8635 - val_loss: 0.7987 - val_accuracy: 0.7626\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3758 - accuracy: 0.8665 - val_loss: 0.8256 - val_accuracy: 0.7539\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3435 - accuracy: 0.8798 - val_loss: 0.9417 - val_accuracy: 0.7367\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3249 - accuracy: 0.8845 - val_loss: 0.8818 - val_accuracy: 0.7423\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3109 - accuracy: 0.8898 - val_loss: 0.9606 - val_accuracy: 0.7474\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2885 - accuracy: 0.8981 - val_loss: 0.8801 - val_accuracy: 0.7604\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2801 - accuracy: 0.8997 - val_loss: 0.9766 - val_accuracy: 0.7469\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2623 - accuracy: 0.9066 - val_loss: 0.9828 - val_accuracy: 0.7474\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2397 - accuracy: 0.9151 - val_loss: 0.9877 - val_accuracy: 0.7558\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2177 - accuracy: 0.9221 - val_loss: 1.0668 - val_accuracy: 0.7396\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2260 - accuracy: 0.9200 - val_loss: 1.0799 - val_accuracy: 0.7479\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1888 - accuracy: 0.9341 - val_loss: 1.0607 - val_accuracy: 0.7504\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1836 - accuracy: 0.9351 - val_loss: 1.0829 - val_accuracy: 0.7504\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1747 - accuracy: 0.9377 - val_loss: 1.1438 - val_accuracy: 0.7488\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1597 - accuracy: 0.9431 - val_loss: 1.1724 - val_accuracy: 0.7472\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1704 - accuracy: 0.9394 - val_loss: 1.1030 - val_accuracy: 0.7602\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1391 - accuracy: 0.9508 - val_loss: 1.1921 - val_accuracy: 0.7499\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1346 - accuracy: 0.9524 - val_loss: 1.2580 - val_accuracy: 0.7457\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1408 - accuracy: 0.9507 - val_loss: 1.1590 - val_accuracy: 0.7586\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1020 - accuracy: 0.9645 - val_loss: 1.3191 - val_accuracy: 0.7485\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1226 - accuracy: 0.9568 - val_loss: 1.2966 - val_accuracy: 0.7493\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1025 - accuracy: 0.9634 - val_loss: 1.3037 - val_accuracy: 0.7598\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1098 - accuracy: 0.9604 - val_loss: 1.3327 - val_accuracy: 0.7553\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1005 - accuracy: 0.9643 - val_loss: 1.4407 - val_accuracy: 0.7475\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0984 - accuracy: 0.9647 - val_loss: 1.3525 - val_accuracy: 0.7610\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0765 - accuracy: 0.9729 - val_loss: 1.3613 - val_accuracy: 0.7603\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0543 - accuracy: 0.9823 - val_loss: 1.5305 - val_accuracy: 0.7489\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0675 - accuracy: 0.9762 - val_loss: 1.5696 - val_accuracy: 0.7497\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.0916 - accuracy: 0.9688 - val_loss: 1.5359 - val_accuracy: 0.7577\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0770 - accuracy: 0.9734 - val_loss: 1.7321 - val_accuracy: 0.7410\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0539 - accuracy: 0.9819 - val_loss: 1.6230 - val_accuracy: 0.7538\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0421 - accuracy: 0.9859 - val_loss: 1.5622 - val_accuracy: 0.7589\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0579 - accuracy: 0.9797 - val_loss: 1.6406 - val_accuracy: 0.7566\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0625 - accuracy: 0.9784 - val_loss: 1.6405 - val_accuracy: 0.7589\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0518 - accuracy: 0.9819 - val_loss: 1.6231 - val_accuracy: 0.7600\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0366 - accuracy: 0.9882 - val_loss: 1.6623 - val_accuracy: 0.7560\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 1.6661 - val_accuracy: 0.7624\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 1.9031 - val_accuracy: 0.7503\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 1.8955 - val_accuracy: 0.7538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6nZcE2hSWio",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` with no data augmentation (groups of 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYJEL7JHSYdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f45bc8a-574c-4daf-d52e-f8c4c8a81c1e"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"EvoNorm2dS0-no-aug-group32\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=32)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-no-aug-group32\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-no-aug-group32</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8540 - accuracy: 0.3168"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Layer EvoNorm2dS0 has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 15s 38ms/step - loss: 1.8540 - accuracy: 0.3168 - val_loss: 1.5713 - val_accuracy: 0.4312\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.3574 - accuracy: 0.5157 - val_loss: 1.2713 - val_accuracy: 0.5572\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.1800 - accuracy: 0.5866 - val_loss: 1.1591 - val_accuracy: 0.6089\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.0583 - accuracy: 0.6317 - val_loss: 1.0219 - val_accuracy: 0.6353\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.9728 - accuracy: 0.6651 - val_loss: 0.9749 - val_accuracy: 0.6640\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.9015 - accuracy: 0.6886 - val_loss: 0.9028 - val_accuracy: 0.6892\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.8444 - accuracy: 0.7100 - val_loss: 0.8556 - val_accuracy: 0.7090\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.8057 - accuracy: 0.7250 - val_loss: 0.8529 - val_accuracy: 0.7076\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.7534 - accuracy: 0.7421 - val_loss: 0.7950 - val_accuracy: 0.7306\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.7248 - accuracy: 0.7522 - val_loss: 0.8025 - val_accuracy: 0.7245\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6863 - accuracy: 0.7666 - val_loss: 0.7388 - val_accuracy: 0.7521\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6569 - accuracy: 0.7768 - val_loss: 0.7941 - val_accuracy: 0.7321\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6286 - accuracy: 0.7848 - val_loss: 0.7433 - val_accuracy: 0.7500\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5982 - accuracy: 0.7959 - val_loss: 0.7073 - val_accuracy: 0.7609\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5595 - accuracy: 0.8056 - val_loss: 0.8161 - val_accuracy: 0.7347\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5457 - accuracy: 0.8109 - val_loss: 0.7396 - val_accuracy: 0.7531\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.5126 - accuracy: 0.8226 - val_loss: 0.7902 - val_accuracy: 0.7465\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4944 - accuracy: 0.8308 - val_loss: 0.8441 - val_accuracy: 0.7328\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4663 - accuracy: 0.8384 - val_loss: 0.8002 - val_accuracy: 0.7527\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4439 - accuracy: 0.8466 - val_loss: 0.7810 - val_accuracy: 0.7544\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.4110 - accuracy: 0.8556 - val_loss: 0.7814 - val_accuracy: 0.7597\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3961 - accuracy: 0.8607 - val_loss: 0.7878 - val_accuracy: 0.7572\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3736 - accuracy: 0.8692 - val_loss: 0.7784 - val_accuracy: 0.7588\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3530 - accuracy: 0.8762 - val_loss: 0.9326 - val_accuracy: 0.7388\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3405 - accuracy: 0.8793 - val_loss: 0.8960 - val_accuracy: 0.7467\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3025 - accuracy: 0.8931 - val_loss: 0.9236 - val_accuracy: 0.7500\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.3000 - accuracy: 0.8944 - val_loss: 0.8735 - val_accuracy: 0.7623\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2828 - accuracy: 0.9011 - val_loss: 0.9414 - val_accuracy: 0.7558\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2714 - accuracy: 0.9025 - val_loss: 0.9432 - val_accuracy: 0.7534\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2515 - accuracy: 0.9108 - val_loss: 0.9508 - val_accuracy: 0.7553\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2311 - accuracy: 0.9185 - val_loss: 1.0418 - val_accuracy: 0.7369\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2096 - accuracy: 0.9256 - val_loss: 1.0257 - val_accuracy: 0.7574\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.2021 - accuracy: 0.9283 - val_loss: 1.0491 - val_accuracy: 0.7462\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1967 - accuracy: 0.9298 - val_loss: 1.0855 - val_accuracy: 0.7438\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1767 - accuracy: 0.9374 - val_loss: 1.0738 - val_accuracy: 0.7584\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1637 - accuracy: 0.9421 - val_loss: 1.1103 - val_accuracy: 0.7583\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1614 - accuracy: 0.9423 - val_loss: 1.1624 - val_accuracy: 0.7548\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1467 - accuracy: 0.9471 - val_loss: 1.1586 - val_accuracy: 0.7615\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1377 - accuracy: 0.9507 - val_loss: 1.3633 - val_accuracy: 0.7404\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1278 - accuracy: 0.9548 - val_loss: 1.2111 - val_accuracy: 0.7578\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1277 - accuracy: 0.9557 - val_loss: 1.3114 - val_accuracy: 0.7458\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1079 - accuracy: 0.9629 - val_loss: 1.3762 - val_accuracy: 0.7470\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0924 - accuracy: 0.9677 - val_loss: 1.4033 - val_accuracy: 0.7511\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1037 - accuracy: 0.9628 - val_loss: 1.5218 - val_accuracy: 0.7343\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1039 - accuracy: 0.9631 - val_loss: 1.3872 - val_accuracy: 0.7611\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0968 - accuracy: 0.9661 - val_loss: 1.5436 - val_accuracy: 0.7387\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.1052 - accuracy: 0.9621 - val_loss: 1.5172 - val_accuracy: 0.7383\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0818 - accuracy: 0.9712 - val_loss: 1.4866 - val_accuracy: 0.7471\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0664 - accuracy: 0.9771 - val_loss: 1.4897 - val_accuracy: 0.7530\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0815 - accuracy: 0.9713 - val_loss: 1.5966 - val_accuracy: 0.7463\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0544 - accuracy: 0.9808 - val_loss: 1.6486 - val_accuracy: 0.7459\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0476 - accuracy: 0.9841 - val_loss: 1.7126 - val_accuracy: 0.7458\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0662 - accuracy: 0.9766 - val_loss: 1.5768 - val_accuracy: 0.7599\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0738 - accuracy: 0.9754 - val_loss: 1.5954 - val_accuracy: 0.7504\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0595 - accuracy: 0.9794 - val_loss: 1.5285 - val_accuracy: 0.7587\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0391 - accuracy: 0.9867 - val_loss: 1.6500 - val_accuracy: 0.7567\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 1.6931 - val_accuracy: 0.7578\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 1.7919 - val_accuracy: 0.7555\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0408 - accuracy: 0.9858 - val_loss: 1.7073 - val_accuracy: 0.7614\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 1.8438 - val_accuracy: 0.7580\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuMJziXASq1L",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` with data augmentation (groups of 8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6VWleEnSqU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94b5a8e4-b3cd-42dd-85b8-db863a430f9e"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"EvoNorm2dS0-data-aug-group8\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=8)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-data-aug-group8\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-data-aug-group8</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1044 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0969 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1051 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0971 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1033 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0954 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1041 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1011 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0958 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1046 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1036 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPX48vJaiGyq",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` with data augmentation (groups of 16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blWXvfkSiKo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a43ff53b-2434-4e1f-89f2-7daff2f47558"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"EvoNorm2dS0-data-aug-group16\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=16)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-data-aug-group16\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-data-aug-group16</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0967 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0949 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1059 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1037 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1015 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0995 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0953 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1035 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1018 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0972 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0935 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1049 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1027 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0961 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFCGEgXCTMCd",
        "colab_type": "text"
      },
      "source": [
        "## With `EvoNorm2dS0` with data augmentation (groups of 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jakxsd_hTGG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8954fc54-5cee-4caf-aed1-dcb3cf8244bb"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"EvoNorm2dS0-data-aug-group32\")\n",
        "\n",
        "# Optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train the model\n",
        "model = minigooglenet_functional(32, 32, 3, 10, norm=EvoNorm2dS0, groups=32)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-data-aug-group32\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/EvoNorm2dS0-data-aug-group32</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 9s 24ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1023 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1025 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0944 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0951 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1023 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1061 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0946 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1044 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1019 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1043 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0957 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0952 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1020 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0969 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1026 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0972 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1049 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 9s 23ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}