{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini_Inception_BN_ReLU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/EvoNorms-in-TensorFlow-2/blob/master/Mini_Inception_BN_ReLU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIDRpbh_NYi1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7208fe51-baf5-4d45-b049-397d94d0c259"
      },
      "source": [
        "# Which GPU? \n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 18 07:34:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-Rvt-ZwXEi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32db6375-a3fe-4f72-bddd-5b1d2af2fc1e"
      },
      "source": [
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtcnpdbgZavs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other imports\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoN2l9PcNgxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the random seeds\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tzaJSLWNhjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up wandb for easy experiment tracking\n",
        "!pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVMZEEWBZ8jf",
        "colab_type": "code",
        "outputId": "bf18d07c-192d-48f4-ed43-5d0cddecf5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Load and preprocess CIFAR10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255.\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgP6ZIWVXQXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementation comes from http://pyimg.co/mac01\n",
        "def minigooglenet_functional(width, height, depth, classes):\n",
        "\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\n",
        "\t\t# define a CONV => BN => RELU pattern\n",
        "\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n",
        "\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef inception_module(x, numK1x1, numK3x3, chanDim):\n",
        "\t\t# define two CONV modules, then concatenate across the\n",
        "\t\t# channel dimension\n",
        "\t\tconv_1x1 = conv_module(x, numK1x1, 1, 1, (1, 1), chanDim)\n",
        "\t\tconv_3x3 = conv_module(x, numK3x3, 3, 3, (1, 1), chanDim)\n",
        "\t\tx = concatenate([conv_1x1, conv_3x3], axis=chanDim)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef downsample_module(x, K, chanDim):\n",
        "\t\t# define the CONV module and POOL, then concatenate\n",
        "\t\t# across the channel dimensions\n",
        "\t\tconv_3x3 = conv_module(x, K, 3, 3, (2, 2), chanDim,\n",
        "\t\t\tpadding=\"valid\")\n",
        "\t\tpool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\t\tx = concatenate([conv_3x3, pool], axis=chanDim)\n",
        "\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\t# initialize the input shape to be \"channels last\" and the\n",
        "\t# channels dimension itself\n",
        "\tinputShape = (height, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\t# define the model input and first CONV module\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = conv_module(inputs, 96, 3, 3, (1, 1), chanDim)\n",
        "\n",
        "\t# two Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 32, 32, chanDim)\n",
        "\tx = inception_module(x, 32, 48, chanDim)\n",
        "\tx = downsample_module(x, 80, chanDim)\n",
        "\n",
        "\t# four Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 112, 48, chanDim)\n",
        "\tx = inception_module(x, 96, 64, chanDim)\n",
        "\tx = inception_module(x, 80, 80, chanDim)\n",
        "\tx = inception_module(x, 48, 96, chanDim)\n",
        "\tx = downsample_module(x, 96, chanDim)\n",
        "\n",
        "\t# two Inception modules followed by global POOL and dropout\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = AveragePooling2D((7, 7))(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\n",
        "\t# softmax classifier\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(classes)(x)\n",
        "\tx = Activation(\"softmax\")(x)\n",
        "\n",
        "\t# create the model\n",
        "\tmodel = Model(inputs, x, name=\"minigooglenet\")\n",
        "\n",
        "\t# return the constructed network architecture\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGDaupx6a5TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparams\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy9af9BYNtU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import wandb's Keras callback\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NkaZ7H2ZsmM",
        "colab_type": "code",
        "outputId": "deb2db27-d0ad-4fc1-c444-079ee184b42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"bn-relu-adam-no-aug\")\n",
        "\n",
        "# Compile and train this model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/bn-relu-adam-no-aug\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/bn-relu-adam-no-aug</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 20s 50ms/step - loss: 1.2624 - accuracy: 0.5445 - val_loss: 2.0476 - val_accuracy: 0.3174\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.7987 - accuracy: 0.7180 - val_loss: 1.2319 - val_accuracy: 0.6011\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.6086 - accuracy: 0.7892 - val_loss: 0.7520 - val_accuracy: 0.7443\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.4908 - accuracy: 0.8306 - val_loss: 0.7714 - val_accuracy: 0.7509\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.4092 - accuracy: 0.8596 - val_loss: 0.9075 - val_accuracy: 0.6802\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.3421 - accuracy: 0.8809 - val_loss: 0.6310 - val_accuracy: 0.7970\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.2802 - accuracy: 0.9023 - val_loss: 0.7355 - val_accuracy: 0.7719\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.2299 - accuracy: 0.9205 - val_loss: 0.6400 - val_accuracy: 0.8016\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.1915 - accuracy: 0.9348 - val_loss: 0.7827 - val_accuracy: 0.7827\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.1566 - accuracy: 0.9455 - val_loss: 1.0637 - val_accuracy: 0.7312\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.1258 - accuracy: 0.9565 - val_loss: 1.1070 - val_accuracy: 0.7494\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.1118 - accuracy: 0.9604 - val_loss: 1.0913 - val_accuracy: 0.7565\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0901 - accuracy: 0.9692 - val_loss: 0.9619 - val_accuracy: 0.7915\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0844 - accuracy: 0.9711 - val_loss: 1.1704 - val_accuracy: 0.7477\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0738 - accuracy: 0.9746 - val_loss: 1.2027 - val_accuracy: 0.7533\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0693 - accuracy: 0.9762 - val_loss: 1.1121 - val_accuracy: 0.7603\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0670 - accuracy: 0.9770 - val_loss: 1.5606 - val_accuracy: 0.7239\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.9185 - val_accuracy: 0.7936\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 1.0396 - val_accuracy: 0.7955\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0502 - accuracy: 0.9829 - val_loss: 0.7247 - val_accuracy: 0.8327\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0453 - accuracy: 0.9843 - val_loss: 0.7723 - val_accuracy: 0.8394\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0456 - accuracy: 0.9846 - val_loss: 2.0354 - val_accuracy: 0.6812\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 0.9259 - val_accuracy: 0.8129\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0376 - accuracy: 0.9876 - val_loss: 1.2413 - val_accuracy: 0.7740\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 1.1634 - val_accuracy: 0.7844\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0317 - accuracy: 0.9893 - val_loss: 1.5080 - val_accuracy: 0.7268\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0417 - accuracy: 0.9857 - val_loss: 0.8609 - val_accuracy: 0.8169\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0376 - accuracy: 0.9870 - val_loss: 1.1235 - val_accuracy: 0.8114\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 0.8891 - val_accuracy: 0.8139\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 1.0534 - val_accuracy: 0.8031\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 1.2050 - val_accuracy: 0.7920\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0327 - accuracy: 0.9888 - val_loss: 0.8789 - val_accuracy: 0.8281\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 1.1749 - val_accuracy: 0.7958\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 1.0941 - val_accuracy: 0.7955\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.8642 - val_accuracy: 0.8331\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.9708 - val_accuracy: 0.8158\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 1.1435 - val_accuracy: 0.8038\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 1.1842 - val_accuracy: 0.8116\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 1.1912 - val_accuracy: 0.7992\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0256 - accuracy: 0.9908 - val_loss: 1.0956 - val_accuracy: 0.8083\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 1.3769 - val_accuracy: 0.7934\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.9922 - val_accuracy: 0.8289\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.9143 - val_accuracy: 0.8346\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 1.0010 - val_accuracy: 0.8249\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0235 - accuracy: 0.9918 - val_loss: 1.1080 - val_accuracy: 0.8162\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 18s 46ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 1.0198 - val_accuracy: 0.8205\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.9278 - val_accuracy: 0.8286\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.8755 - val_accuracy: 0.8464\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.9444 - val_accuracy: 0.8406\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.8310 - val_accuracy: 0.8509\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 1.4291 - val_accuracy: 0.7832\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0185 - accuracy: 0.9932 - val_loss: 1.0575 - val_accuracy: 0.8207\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 1.1556 - val_accuracy: 0.7928\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 1.2984 - val_accuracy: 0.7626\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 1.1321 - val_accuracy: 0.8194\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 1.1770 - val_accuracy: 0.8104\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 1.1656 - val_accuracy: 0.8083\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.7455 - val_accuracy: 0.8582\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.9333 - val_accuracy: 0.8356\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.9894 - val_accuracy: 0.8358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg61Q51Tdten",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try one-hot encoding the labels and then see\n",
        "y_train_ohe = tf.keras.utils.to_categorical(y_train)\n",
        "y_test_ohe = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyDjh7f9eNs0",
        "colab_type": "code",
        "outputId": "d3c9b39c-c5c1-4d55-d8d5-a91030e0a814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"bn-relu-adam-no-aug-ohe\")\n",
        "\n",
        "# Compile and train this model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/bn-relu-adam-no-aug-ohe\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/bn-relu-adam-no-aug-ohe</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 20s 50ms/step - loss: 1.2584 - accuracy: 0.5458 - val_loss: 1.9984 - val_accuracy: 0.3539\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 19s 49ms/step - loss: 0.7739 - accuracy: 0.7303 - val_loss: 1.2209 - val_accuracy: 0.6240\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 19s 49ms/step - loss: 0.5982 - accuracy: 0.7944 - val_loss: 0.8917 - val_accuracy: 0.6979\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 19s 49ms/step - loss: 0.4890 - accuracy: 0.8312 - val_loss: 0.7485 - val_accuracy: 0.7473\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.4051 - accuracy: 0.8615 - val_loss: 0.9135 - val_accuracy: 0.7051\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.3343 - accuracy: 0.8843 - val_loss: 0.8170 - val_accuracy: 0.7421\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.2810 - accuracy: 0.9036 - val_loss: 1.2142 - val_accuracy: 0.6600\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.2301 - accuracy: 0.9194 - val_loss: 1.0940 - val_accuracy: 0.6991\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.1898 - accuracy: 0.9346 - val_loss: 0.8794 - val_accuracy: 0.7555\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.1560 - accuracy: 0.9462 - val_loss: 0.7666 - val_accuracy: 0.7778\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.1351 - accuracy: 0.9533 - val_loss: 1.1735 - val_accuracy: 0.7313\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.1097 - accuracy: 0.9621 - val_loss: 0.8972 - val_accuracy: 0.7784\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0922 - accuracy: 0.9689 - val_loss: 0.9659 - val_accuracy: 0.7713\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0828 - accuracy: 0.9727 - val_loss: 0.7575 - val_accuracy: 0.7928\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0764 - accuracy: 0.9740 - val_loss: 1.2623 - val_accuracy: 0.7522\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0709 - accuracy: 0.9758 - val_loss: 0.9660 - val_accuracy: 0.7823\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0653 - accuracy: 0.9772 - val_loss: 1.1906 - val_accuracy: 0.7583\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0643 - accuracy: 0.9781 - val_loss: 1.2345 - val_accuracy: 0.7664\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 1.2395 - val_accuracy: 0.7667\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0566 - accuracy: 0.9809 - val_loss: 0.9324 - val_accuracy: 0.8110\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 0.7554 - val_accuracy: 0.8264\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.8985 - val_accuracy: 0.8240\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0518 - accuracy: 0.9824 - val_loss: 1.6141 - val_accuracy: 0.7163\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.8382 - val_accuracy: 0.8261\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 1.1199 - val_accuracy: 0.7757\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0370 - accuracy: 0.9870 - val_loss: 1.3308 - val_accuracy: 0.7536\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0406 - accuracy: 0.9857 - val_loss: 1.1043 - val_accuracy: 0.7992\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 1.1680 - val_accuracy: 0.7799\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 19s 49ms/step - loss: 0.0338 - accuracy: 0.9888 - val_loss: 0.7113 - val_accuracy: 0.8469\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 1.2838 - val_accuracy: 0.7962\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0433 - accuracy: 0.9852 - val_loss: 1.0941 - val_accuracy: 0.7969\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.9259 - val_accuracy: 0.8250\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 1.0025 - val_accuracy: 0.8132\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.9334 - val_accuracy: 0.8345\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.7463 - val_accuracy: 0.8420\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.9994 - val_accuracy: 0.8261\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 1.1257 - val_accuracy: 0.8102\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 1.0070 - val_accuracy: 0.8180\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0281 - accuracy: 0.9904 - val_loss: 0.8709 - val_accuracy: 0.8389\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 1.1561 - val_accuracy: 0.8059\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 1.0353 - val_accuracy: 0.8364\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 0.8807 - val_accuracy: 0.8378\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.7558 - val_accuracy: 0.8475\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 1.0869 - val_accuracy: 0.8309\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 1.3860 - val_accuracy: 0.7870\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.7498 - val_accuracy: 0.8541\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 1.0297 - val_accuracy: 0.8284\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 1.0181 - val_accuracy: 0.8329\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 1.0318 - val_accuracy: 0.8228\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 1.1096 - val_accuracy: 0.8029\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 0.9102 - val_accuracy: 0.8457\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.7214 - val_accuracy: 0.8586\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 1.0726 - val_accuracy: 0.8334\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 1.0249 - val_accuracy: 0.8221\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.8943 - val_accuracy: 0.8406\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.9987 - val_accuracy: 0.8345\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.9654 - val_accuracy: 0.8360\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 1.3203 - val_accuracy: 0.7973\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.8278 - val_accuracy: 0.8546\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 1.0488 - val_accuracy: 0.8115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJqY9yadgpka",
        "colab_type": "code",
        "outputId": "e35c93da-6dd6-4403-ee6f-64ca8ffad364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"bn-relu-sgd-no-aug-one-hot\")\n",
        "\n",
        "# Let's try changing the optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train this model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train_ohe,\n",
        "                    validation_data=(X_test, y_test_ohe),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[WandbCallback()])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/bn-relu-sgd-no-aug-one-hot\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/bn-relu-sgd-no-aug-one-hot</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 19s 50ms/step - loss: 1.4082 - accuracy: 0.4863 - val_loss: 2.1256 - val_accuracy: 0.2715\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.9548 - accuracy: 0.6590 - val_loss: 1.4909 - val_accuracy: 0.5194\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.7681 - accuracy: 0.7282 - val_loss: 0.9395 - val_accuracy: 0.6679\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.6520 - accuracy: 0.7734 - val_loss: 1.1169 - val_accuracy: 0.6309\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.5607 - accuracy: 0.8044 - val_loss: 1.0874 - val_accuracy: 0.6387\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.4810 - accuracy: 0.8316 - val_loss: 0.9093 - val_accuracy: 0.7136\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.4131 - accuracy: 0.8573 - val_loss: 0.8429 - val_accuracy: 0.7291\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.3496 - accuracy: 0.8795 - val_loss: 0.9008 - val_accuracy: 0.7169\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.2926 - accuracy: 0.8993 - val_loss: 0.9118 - val_accuracy: 0.7393\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.2408 - accuracy: 0.9177 - val_loss: 1.1399 - val_accuracy: 0.7189\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.1936 - accuracy: 0.9347 - val_loss: 0.8479 - val_accuracy: 0.7540\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.1488 - accuracy: 0.9524 - val_loss: 1.3002 - val_accuracy: 0.6981\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.1132 - accuracy: 0.9641 - val_loss: 0.8211 - val_accuracy: 0.7643\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0839 - accuracy: 0.9749 - val_loss: 0.9888 - val_accuracy: 0.7504\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0638 - accuracy: 0.9814 - val_loss: 0.8776 - val_accuracy: 0.7732\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0508 - accuracy: 0.9854 - val_loss: 0.8952 - val_accuracy: 0.7771\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 19s 49ms/step - loss: 0.0377 - accuracy: 0.9906 - val_loss: 0.7705 - val_accuracy: 0.8137\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 19s 49ms/step - loss: 0.0301 - accuracy: 0.9928 - val_loss: 0.7569 - val_accuracy: 0.8091\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0226 - accuracy: 0.9953 - val_loss: 0.9011 - val_accuracy: 0.7960\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0181 - accuracy: 0.9966 - val_loss: 0.8262 - val_accuracy: 0.8053\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.8221 - val_accuracy: 0.8108\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.9153 - val_accuracy: 0.8034\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.8202 - val_accuracy: 0.8166\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.7111 - val_accuracy: 0.8296\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.6799 - val_accuracy: 0.8361\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.7321 - val_accuracy: 0.8382\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.6901 - val_accuracy: 0.8394\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.7438 - val_accuracy: 0.8276\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.6853 - val_accuracy: 0.8395\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.7015 - val_accuracy: 0.8399\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.7141 - val_accuracy: 0.8354\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.7042 - val_accuracy: 0.8383\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.7047 - val_accuracy: 0.8395\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.7043 - val_accuracy: 0.8407\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.7384 - val_accuracy: 0.8362\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.6999 - val_accuracy: 0.8417\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.7425 - val_accuracy: 0.8376\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.7175 - val_accuracy: 0.8411\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.7095 - val_accuracy: 0.8394\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8428\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8420\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.7022 - val_accuracy: 0.8431\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8416\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.7127 - val_accuracy: 0.8397\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.7034 - val_accuracy: 0.8424\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8430\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8424\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.7070 - val_accuracy: 0.8428\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.7316 - val_accuracy: 0.8395\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8427\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.7171 - val_accuracy: 0.8416\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8441\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.8411\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8408\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.7342 - val_accuracy: 0.8396\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.7207 - val_accuracy: 0.8414\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8447\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 19s 48ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.7202 - val_accuracy: 0.8420\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8425\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 19s 47ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.7195 - val_accuracy: 0.8441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B3-oGcpjOYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try with data augmentation\n",
        "aug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=18, \n",
        "    zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, \n",
        "    shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiFkHoZmjcJ-",
        "colab_type": "code",
        "outputId": "b6c65731-2133-49f4-fe06-c01df7ed5f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"evonorm-tf2\", id=\"bn-relu-sgd-aug-ohe\")\n",
        "\n",
        "# Let's try changing the optimizer\n",
        "opt = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9, decay=1e-2 / EPOCHS)\n",
        "\n",
        "# Compile and train this model\n",
        "model = minigooglenet_functional(32, 32, 3, 10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "history = model.fit(aug.flow(X_train, y_train_ohe),\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "\tvalidation_data=(X_test, y_test_ohe),\n",
        "\tvalidation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "\tepochs=EPOCHS,\n",
        "\tcallbacks=[WandbCallback()])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/bn-relu-sgd-aug-ohe\" target=\"_blank\">https://app.wandb.ai/sayakpaul/evonorm-tf2/runs/bn-relu-sgd-aug-ohe</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - 14s 35ms/step - loss: 1.9018 - accuracy: 0.3034 - val_loss: 1.6943 - val_accuracy: 0.3652\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 1.5763 - accuracy: 0.4292 - val_loss: 2.2856 - val_accuracy: 0.2852\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 1.4258 - accuracy: 0.4808 - val_loss: 1.8869 - val_accuracy: 0.4210\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 13s 33ms/step - loss: 1.3485 - accuracy: 0.5188 - val_loss: 1.1502 - val_accuracy: 0.5886\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 1.2429 - accuracy: 0.5530 - val_loss: 1.2371 - val_accuracy: 0.5524\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 1.1927 - accuracy: 0.5780 - val_loss: 1.1611 - val_accuracy: 0.5992\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 1.1465 - accuracy: 0.5930 - val_loss: 1.1244 - val_accuracy: 0.6067\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 1.0946 - accuracy: 0.6151 - val_loss: 1.1987 - val_accuracy: 0.5966\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 1.0423 - accuracy: 0.6374 - val_loss: 0.9664 - val_accuracy: 0.6607\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 1.0140 - accuracy: 0.6435 - val_loss: 1.1982 - val_accuracy: 0.6120\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.9563 - accuracy: 0.6677 - val_loss: 1.3672 - val_accuracy: 0.5794\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.9589 - accuracy: 0.6672 - val_loss: 1.2307 - val_accuracy: 0.5923\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.9003 - accuracy: 0.6816 - val_loss: 1.2342 - val_accuracy: 0.6119\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.8804 - accuracy: 0.6964 - val_loss: 0.9050 - val_accuracy: 0.6958\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.8663 - accuracy: 0.7023 - val_loss: 0.8383 - val_accuracy: 0.7171\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.8475 - accuracy: 0.7088 - val_loss: 0.8214 - val_accuracy: 0.7287\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.8179 - accuracy: 0.7199 - val_loss: 0.7560 - val_accuracy: 0.7450\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.8027 - accuracy: 0.7184 - val_loss: 0.9029 - val_accuracy: 0.6951\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.7976 - accuracy: 0.7292 - val_loss: 0.9175 - val_accuracy: 0.7075\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.7792 - accuracy: 0.7313 - val_loss: 0.8857 - val_accuracy: 0.7234\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.7562 - accuracy: 0.7423 - val_loss: 0.9159 - val_accuracy: 0.6904\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.7411 - accuracy: 0.7448 - val_loss: 0.8459 - val_accuracy: 0.7447\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.7351 - accuracy: 0.7453 - val_loss: 0.6678 - val_accuracy: 0.7698\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.7121 - accuracy: 0.7532 - val_loss: 0.6872 - val_accuracy: 0.7732\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.6934 - accuracy: 0.7616 - val_loss: 0.7074 - val_accuracy: 0.7721\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.6947 - accuracy: 0.7597 - val_loss: 0.8034 - val_accuracy: 0.7439\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 13s 33ms/step - loss: 0.6718 - accuracy: 0.7710 - val_loss: 0.6603 - val_accuracy: 0.7809\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.6828 - accuracy: 0.7652 - val_loss: 0.6606 - val_accuracy: 0.7823\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.6519 - accuracy: 0.7737 - val_loss: 0.6330 - val_accuracy: 0.7875\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.6515 - accuracy: 0.7736 - val_loss: 0.5806 - val_accuracy: 0.8049\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.6491 - accuracy: 0.7835 - val_loss: 0.6080 - val_accuracy: 0.8011\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.6534 - accuracy: 0.7772 - val_loss: 0.5890 - val_accuracy: 0.8077\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.6196 - accuracy: 0.7889 - val_loss: 0.5691 - val_accuracy: 0.8148\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.6204 - accuracy: 0.7883 - val_loss: 0.6952 - val_accuracy: 0.7789\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: 0.6095 - accuracy: 0.7913 - val_loss: 0.6785 - val_accuracy: 0.7745\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.6128 - accuracy: 0.7909 - val_loss: 0.5032 - val_accuracy: 0.8327\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: 0.5669 - accuracy: 0.8095 - val_loss: 0.8119 - val_accuracy: 0.7611\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5943 - accuracy: 0.7994 - val_loss: 0.6091 - val_accuracy: 0.8057\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5794 - accuracy: 0.8011 - val_loss: 0.6681 - val_accuracy: 0.7856\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: 0.5832 - accuracy: 0.8002 - val_loss: 0.5524 - val_accuracy: 0.8206\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5652 - accuracy: 0.8103 - val_loss: 0.7674 - val_accuracy: 0.7770\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5565 - accuracy: 0.8072 - val_loss: 0.6132 - val_accuracy: 0.8074\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5521 - accuracy: 0.8115 - val_loss: 0.7851 - val_accuracy: 0.7713\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.5548 - accuracy: 0.8120 - val_loss: 0.5198 - val_accuracy: 0.8247\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5386 - accuracy: 0.8140 - val_loss: 0.6185 - val_accuracy: 0.8036\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5373 - accuracy: 0.8171 - val_loss: 0.6391 - val_accuracy: 0.8044\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: 0.5447 - accuracy: 0.8162 - val_loss: 0.6077 - val_accuracy: 0.8173\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: 0.5391 - accuracy: 0.8192 - val_loss: 0.6096 - val_accuracy: 0.8070\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5237 - accuracy: 0.8213 - val_loss: 0.6623 - val_accuracy: 0.7920\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5127 - accuracy: 0.8244 - val_loss: 0.4946 - val_accuracy: 0.8302\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5216 - accuracy: 0.8202 - val_loss: 0.5380 - val_accuracy: 0.8274\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5188 - accuracy: 0.8248 - val_loss: 0.5744 - val_accuracy: 0.8182\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: 0.4918 - accuracy: 0.8310 - val_loss: 0.5578 - val_accuracy: 0.8143\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: 0.5000 - accuracy: 0.8269 - val_loss: 0.6032 - val_accuracy: 0.8129\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 12s 31ms/step - loss: 0.4932 - accuracy: 0.8328 - val_loss: 0.6318 - val_accuracy: 0.8020\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.5062 - accuracy: 0.8294 - val_loss: 0.5247 - val_accuracy: 0.8273\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.4698 - accuracy: 0.8389 - val_loss: 0.4864 - val_accuracy: 0.8359\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.4949 - accuracy: 0.8280 - val_loss: 0.5131 - val_accuracy: 0.8316\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 13s 32ms/step - loss: 0.4930 - accuracy: 0.8287 - val_loss: 0.4759 - val_accuracy: 0.8444\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 12s 32ms/step - loss: 0.4886 - accuracy: 0.8345 - val_loss: 0.5049 - val_accuracy: 0.8369\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}